<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>JAVA学习笔记-Kafka | Muite</title><meta name="author" content="Muite"><meta name="copyright" content="Muite"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="运行启动Kafkajava8+ kafka可以使用zookeeper或kraft启动，但只能使用其中一种方式，不能同时使用； kraft是kafka的内置共识机制，用于取代zookeeper 下载kafka完成后：  使用zookeeper启动kafka：  进入kafka的bin目录中， zookeeper-server-start.sh ..&#x2F;config&#x2F;zookeeper.properti">
<meta property="og:type" content="article">
<meta property="og:title" content="JAVA学习笔记-Kafka">
<meta property="og:url" content="https://mutesniper.github.io/2025/04/11/Kafka/index.html">
<meta property="og:site_name" content="Muite">
<meta property="og:description" content="运行启动Kafkajava8+ kafka可以使用zookeeper或kraft启动，但只能使用其中一种方式，不能同时使用； kraft是kafka的内置共识机制，用于取代zookeeper 下载kafka完成后：  使用zookeeper启动kafka：  进入kafka的bin目录中， zookeeper-server-start.sh ..&#x2F;config&#x2F;zookeeper.properti">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://img.alicdn.com/bao/uploaded/i3/2200690044395/O1CN012NL22Q1iKxHYWb17f_!!2200690044395.jpg">
<meta property="article:published_time" content="2025-04-11T04:46:00.000Z">
<meta property="article:modified_time" content="2025-04-11T01:12:11.969Z">
<meta property="article:author" content="Muite">
<meta property="article:tag" content="JAVA">
<meta property="article:tag" content="note">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img.alicdn.com/bao/uploaded/i3/2200690044395/O1CN012NL22Q1iKxHYWb17f_!!2200690044395.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "JAVA学习笔记-Kafka",
  "url": "https://mutesniper.github.io/2025/04/11/Kafka/",
  "image": "https://img.alicdn.com/bao/uploaded/i3/2200690044395/O1CN012NL22Q1iKxHYWb17f_!!2200690044395.jpg",
  "datePublished": "2025-04-11T04:46:00.000Z",
  "dateModified": "2025-04-11T01:12:11.969Z",
  "author": [
    {
      "@type": "Person",
      "name": "Muite",
      "url": "https://mutesniper.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://mutesniper.github.io/2025/04/11/Kafka/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'JAVA学习笔记-Kafka',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-footer-beautify@1.0.0/lib/runtime.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background-image: url(/img/1990ee2c41564e328f35ac72f555f170.jpeg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="https://img.alicdn.com/bao/uploaded/i3/2200690044395/O1CN012NL22Q1iKxHYWb17f_!!2200690044395.jpg" onerror="this.onerror=null;this.src='/null'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">17</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"></a><a class="nav-page-title" href="/"><span class="site-name">JAVA学习笔记-Kafka</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">JAVA学习笔记-Kafka</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-04-11T04:46:00.000Z" title="Created 2025-04-11 12:46:00">2025-04-11</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-04-11T01:12:11.969Z" title="Updated 2025-04-11 09:12:11">2025-04-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/java-note/">java-note</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="运行启动Kafka"><a href="#运行启动Kafka" class="headerlink" title="运行启动Kafka"></a>运行启动Kafka</h1><p>java8+</p>
<p>kafka可以使用zookeeper或kraft启动，但只能使用其中一种方式，不能同时使用；</p>
<p>kraft是kafka的内置共识机制，用于取代zookeeper</p>
<p>下载kafka完成后：</p>
<ul>
<li>使用zookeeper启动kafka：</li>
</ul>
<p>进入kafka的bin目录中，</p>
<p><code>zookeeper-server-start.sh ../config/zookeeper.properties &amp;</code>：启动zookeeper（因为kafka安装包自带zookeeper的jar包），可以在不安装zookeeper的情况下运行zookeeper。<code>&amp;</code>表示后台运行。</p>
<p><code>kafka-server-start.sh ../config/server.properties &amp;</code>：启动kafka</p>
<p><code>kafka-server-stop.sh ../config/server.properties</code>：关闭kafka</p>
<p><code>zookeeper-server-start.sh ../config/zookeeper.properties</code>：关闭zookeeper</p>
<ul>
<li><p>使用kraft启动kafka</p>
<p>进入kafka的bin目录中，</p>
</li>
</ul>
<ol>
<li>生成 Cluster UUID（集群UUID）：<code>kafka-storage.sh random-uuid</code></li>
<li><code>kafka-storage.sh format -t 生成的uuid -c ../config/kraft/server.properties</code></li>
<li>启动kafka：<code>kafka-server.start.sh ../config/kraft/server.properties &amp;</code></li>
<li>关闭kafka：<code>kafka-server.stop.sh ../config/kraft/server.properties </code></li>
</ol>
<ul>
<li>docker:</li>
</ul>
<ol>
<li>拉取kafka的镜像：<code>docker pull apache/kafka:3.7.0</code></li>
<li>启动kafka的docker容器：<code>docker run -p 9092:9092 apache/kafka:3.7.0</code></li>
</ol>
<h1 id="以下均基于kraft启动"><a href="#以下均基于kraft启动" class="headerlink" title="以下均基于kraft启动"></a>以下均基于kraft启动</h1><h1 id="外部连接kafka"><a href="#外部连接kafka" class="headerlink" title="外部连接kafka"></a>外部连接kafka</h1><p>在idea中下载插件kafka，启动kafka后测试连接发现连接不上。这是由于配置的问题。</p>
<p>Docker容器的kafka有三种配置启动方式：</p>
<ul>
<li>默认配置：使用kafka容器的默认配置，外部是连接不上的</li>
<li>文件输入：提供一个本地kafka属性配置文件，覆盖docker容器中的默认配置文件</li>
<li>环境变量：通过env变量定义kafka属性，覆盖默认配置中对应该属性的值</li>
</ul>
<h3 id="文件覆盖："><a href="#文件覆盖：" class="headerlink" title="文件覆盖："></a>文件覆盖：</h3><p>进入kafka：</p>
<p><code>docker exec -it 容器id /bin/bash</code></p>
<p>配置文件<code>server.properties</code>就在<code>/etc/kafka/docker</code>目录下</p>
<p>将容器中的配置文件复制一份到宿主机上:</p>
<p><code>docker cp 容器id:/etc/kafka/docker/server.properties 目的地目录</code></p>
<p>将复制的配置文件进行修改：</p>
<p><code>listeners=PLAINTEXT://0.0.0.0:9092</code></p>
<p><code>advertised.listeners=PLAINTEXT://&lt;宿主机IP&gt;:9092</code></p>
<p>(其实这两者如果采用 本笔记启动-(1)方法启动，自动就会设置这两个配置 )</p>
<p>配置文件映射:<br>某些 Kafka 镜像（例如官方镜像或其他流行的社区镜像）会在启动脚本中检查特定路径（如 &#x2F;mnt&#x2F;shared&#x2F;config）是否存在配置文件。</p>
<p><code>docker run -v /home/mutesniper/code/docker:/mnt/shared/config -p 9092:9092 apache/kafka:3.7.0</code></p>
<p>再进行远程连接就成功了。</p>
<h1 id="Springboot集成kafka"><a href="#Springboot集成kafka" class="headerlink" title="Springboot集成kafka"></a>Springboot集成kafka</h1><p>在springboot项目创建好后，需要进行相关配置。</p>
<ul>
<li>服务器连接:<code>spring.kafka.bootstrap-servers:宿主机IP：端口</code></li>
<li>生产者（配置项参考KafkaProperties.java）:后面根据需要进行配置</li>
<li>消费者（配置项参考KafkaProperties.java）:后面根据需要进行配置</li>
</ul>
<h2 id="生产者"><a href="#生产者" class="headerlink" title="生产者"></a>生产者</h2><h3 id="Kaka几个概念"><a href="#Kaka几个概念" class="headerlink" title="*Kaka几个概念"></a>*Kaka几个概念</h3><p>主题Topic</p>
<ul>
<li><strong>定义</strong>：主题是 Kafka 中消息的分类或名称。生产者将消息发布到特定的主题，而消费者订阅这些主题以接收消息。</li>
<li>特点<ul>
<li>每个消息都属于一个特定的主题。</li>
<li>主题可以有多个分区（Partition），这有助于并行处理和扩展性。</li>
</ul>
</li>
</ul>
<p>分区Partition</p>
<ul>
<li><strong>定义</strong>：每个主题可以分为多个分区，这是 Kafka 实现高吞吐量和水平扩展的关键机制。</li>
<li>特点<ul>
<li>分区内的消息是有序的，但跨分区的消息顺序不保证。</li>
<li>每个分区可以被复制（Replication）以提高容错能力。</li>
<li>消费者组中的消费者实例会分配到不同的分区上进行消费，实现负载均衡。</li>
</ul>
</li>
</ul>
<p>偏移量Offset</p>
<ul>
<li><strong>定义</strong>：偏移量是每个分区中每条消息的唯一标识符，表示消息在分区中的位置。</li>
<li>用途<ul>
<li>消费者通过记录偏移量来追踪已经消费的消息，以便于从上次停止的地方继续消费。</li>
<li>偏移量由消费者提交给 Kafka 或外部存储系统（如 Zookeeper）。</li>
</ul>
</li>
</ul>
<p>生产者Producer</p>
<ul>
<li><strong>定义</strong>：生产者是向 Kafka 主题发送消息的应用程序。</li>
<li>功能<ul>
<li>生产者可以选择将消息发送到特定的分区，也可以让 Kafka 根据某种策略（如哈希算法）自动选择分区。</li>
<li>生产者还可以配置消息的确认机制（如是否等待副本同步完成）。</li>
</ul>
</li>
</ul>
<p>消费者Consumer</p>
<ul>
<li><strong>定义</strong>：消费者是从 Kafka 主题读取消息的应用程序。</li>
<li>功能<ul>
<li>消费者通常以消费者组的形式工作，同一组内的消费者不会重复消费相同的消息。</li>
<li>消费者需要管理自己的偏移量，并决定何时提交偏移量。</li>
</ul>
</li>
</ul>
<p>消费者组Consumer Group</p>
<ul>
<li><strong>定义</strong>：消费者组是一组共同消费某个或某些主题的消费者的集合。</li>
<li>特点<ul>
<li>同一消费者组内的消费者之间实现负载均衡，即每个分区只能被同一个消费者组内的一个消费者消费。</li>
<li>不同消费者组之间的消费者可以独立消费相同的消息。</li>
</ul>
</li>
</ul>
<p>Broker</p>
<ul>
<li><strong>定义</strong>：Broker 是 Kafka 集群中的一个节点，负责存储数据、处理客户端请求（生产和消费）以及集群间的数据复制。</li>
<li>特点<ul>
<li>Kafka 集群由多个 Broker 组成，提供高可用性和扩展性。</li>
<li>每个 Broker 可以持有多个主题的不同分区。</li>
</ul>
</li>
</ul>
<p>日志Log</p>
<ul>
<li><strong>定义</strong>：在 Kafka 中，主题的每个分区实际上是一个分布式的提交日志。</li>
<li>特性<ul>
<li>日志是一种持久化、有序且不可变的序列，新的消息不断追加到日志末尾。</li>
<li>日志支持长时间保存，具体时长取决于配置的保留策略。</li>
</ul>
</li>
</ul>
<p>Zookeeper</p>
<ul>
<li><strong>定义</strong>：尽管较新版本的 Kafka 已经开始减少对 Zookeeper 的依赖，传统上，Kafka 使用 Zookeeper 来管理和协调 Kafka 集群的状态。</li>
<li>功能<ul>
<li>维护 Kafka Broker 的元数据信息（如主题、分区等）。</li>
<li>协助选举领导者分区（Leader Partition）。</li>
<li>管理消费者组的偏移量。</li>
</ul>
</li>
</ul>
<h3 id="Event生产"><a href="#Event生产" class="headerlink" title="Event生产"></a>Event生产</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">EventProducer</span> &#123;</span><br><span class="line">    <span class="comment">//加入spring-kafka依赖，并且我们配置好了yml，</span></span><br><span class="line">    <span class="comment">// springboot自动配置好了kafka，自动装配好了kafkaTemplate这个Bean</span></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> KafkaTemplate&lt;String, String&gt; kafkaTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sendEvent</span><span class="params">()</span> &#123;</span><br><span class="line">        kafkaTemplate.send(<span class="string">&quot;hello-topic&quot;</span>, <span class="string">&quot;hello kafka!&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>测试：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> EventProducer eventProducer;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">test01</span><span class="params">()</span> &#123;</span><br><span class="line">    eventProducer.sendEvent();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>发送成功</p>
<h3 id="Event消费"><a href="#Event消费" class="headerlink" title="Event消费"></a>Event消费</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">EventConsumer</span> &#123;</span><br><span class="line">    <span class="comment">//采用监听的方式接收事件（消息）</span></span><br><span class="line">    <span class="comment">//指定订阅的topic和消费者所在消费者组</span></span><br><span class="line">    <span class="meta">@KafkaListener(topics=&quot;hello-topic&quot;,groupId = &quot;hello-group&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onEvent</span><span class="params">(String message)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;读取到的消息:&quot;</span>+message);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>通过这种方式，在springboot项目启动后，此consumer就能自动监听hello-topic主题发送的消息。</p>
<p><strong>但是这种方式仅仅只能监听项目启动后发送的消息，那么要怎么获取之前已经发送的消息呢。</strong></p>
<p>也就是：<br>默认情况下，当启动一个新的消费者组时，它会从每个分区的最新偏移量（即该分区中最后一条消息的下一个位置）开始消费。如果希望从第一条消息开始消费，需要将消费者的<code>auto.offset.reset</code>设置为earlist</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">kafka:</span></span><br><span class="line">    <span class="attr">consumer:</span></span><br><span class="line">        <span class="attr">auto-offset-reset:</span> <span class="string">earliest</span></span><br></pre></td></tr></table></figure>



<p>但是，我们在启动主程序后发现并没有读到，这是因为</p>
<p>如果之前已经用相同的消费者组id消费过该Topic , 并且kafka已经保存了该消费者组的偏移量，即使设置了auto..配置，该设置也不会产生实际效果，因为kafka只会在找不到偏移量时使用这个配置。在这种情况下，需要手动重置偏移量或使用一个新的消费者组id。</p>
<p>先使用第二种方法：</p>
<p><code>groupid=&quot;hello-group-02&quot;</code>，发现可以从头读取</p>
<p>观察一下kafka插件显示的信息:</p>
<p>hello-topic:<img src="C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-07 095121.png" alt="屏幕截图 2025-04-07 095121" style="zoom:75%;" /></p>
<p>hello-group:<img src="C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-07 095126.png" alt="屏幕截图 2025-04-07 095126" style="zoom:75%;" /></p>
<p>hello-group-02:<img src="C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-07 095131.png" alt="屏幕截图 2025-04-07 095131" style="zoom:75%;" /></p>
<p>再使用第一种方法</p>
<ul>
<li><p>防火墙开启9092端口</p>
</li>
<li><p>进入docker容器</p>
</li>
<li><p>使用命令<code>/opt/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group 组名</code>查看消费者组情况。</p>
</li>
<li><p><code>/opt/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 \                      </code></p>
<p><code>--group 组名 \ </code></p>
<p><code>--reset-offsets \ </code></p>
<p><code>--to-earliest \ </code></p>
<p><code>--execute \ </code></p>
<p><code>--topic  topic名</code></p>
<p>可以将偏移量重置到开头。（还可以重置到最新、按偏移量重置、按时间重置）</p>
</li>
</ul>
<h4 id="消费时偏移量策略的配置"><a href="#消费时偏移量策略的配置" class="headerlink" title="消费时偏移量策略的配置"></a>消费时偏移量策略的配置</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  kafka:</span><br><span class="line">    consumer:</span><br><span class="line">        auto-offset-reset: </span><br></pre></td></tr></table></figure>

<p>取值：</p>
<ul>
<li><p>earlist：当各分区没有初始偏移量或当前偏移量无效时，自动将偏移量重置为最早的偏移量</p>
</li>
<li><p>latest：如果没有找到初始偏移量或当前偏移量无效，自动将偏移量重置为最新的偏移量</p>
</li>
<li><p>none：如果没有找到初始偏移量或当前偏移量无效，则抛出异常。</p>
</li>
</ul>
<h3 id="发送Message对象消息"><a href="#发送Message对象消息" class="headerlink" title="发送Message对象消息"></a>发送Message对象消息</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sendEvent2</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">//通过构建器模式创建Message对象(springframework包下的)</span></span><br><span class="line">    <span class="type">Message</span> <span class="variable">message</span> <span class="operator">=</span> MessageBuilder.withPayload(<span class="string">&quot;hello kafka!&quot;</span>)</span><br><span class="line">            <span class="comment">//在header中放置topic的名字</span></span><br><span class="line">            .setHeader(KafkaHeaders.TOPIC, <span class="string">&quot;hello-topic-02&quot;</span>)</span><br><span class="line">            .build();</span><br><span class="line">    kafkaTemplate.send(message);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="keyword">void</span> <span class="title function_">test02</span><span class="params">()</span> &#123;</span><br><span class="line">    eventProducer.sendEvent2();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="发送ProducerRecord对象消息"><a href="#发送ProducerRecord对象消息" class="headerlink" title="发送ProducerRecord对象消息"></a>发送ProducerRecord对象消息</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sendEvent3</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">//消息头,允许你附加一些元数据信息到消息上(key-value)</span></span><br><span class="line">    <span class="comment">//消费者接收到该消息后，可以拿到消息头信息</span></span><br><span class="line">    Headers headers=<span class="keyword">new</span> <span class="title class_">RecordHeaders</span>();</span><br><span class="line">    headers.add(<span class="string">&quot;phone&quot;</span>,<span class="string">&quot;11111111&quot;</span>.getBytes(StandardCharsets.UTF_8));</span><br><span class="line">    <span class="comment">//第一个泛型是key，第二个泛型是value</span></span><br><span class="line">    <span class="comment">//这里采用最全的构造函数对参数进行示范</span></span><br><span class="line">    <span class="comment">//还有其他更简单的构造函数</span></span><br><span class="line">    ProducerRecord&lt;String, String&gt; record = <span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(</span><br><span class="line">            <span class="string">&quot;hello-topic-03&quot;</span>, <span class="comment">//topic</span></span><br><span class="line">            <span class="number">0</span>,  <span class="comment">//partition</span></span><br><span class="line">            System.currentTimeMillis(), <span class="comment">//时间戳</span></span><br><span class="line">            <span class="string">&quot;key1&quot;</span>, <span class="comment">//key</span></span><br><span class="line">            <span class="string">&quot;hello kafka!&quot;</span>, <span class="comment">//value</span></span><br><span class="line">            headers); <span class="comment">//消息头</span></span><br><span class="line">    kafkaTemplate.send(record);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="发送指定分区的消息"><a href="#发送指定分区的消息" class="headerlink" title="发送指定分区的消息"></a>发送指定分区的消息</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sendEvent4</span><span class="params">()</span> &#123;</span><br><span class="line">    kafkaTemplate.send(<span class="string">&quot;hello-topic-02&quot;</span>, <span class="number">0</span>,System.currentTimeMillis(),<span class="string">&quot;key2&quot;</span>,<span class="string">&quot;hello kafka!&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>send方法有6个重载的方法，上面仅讲了一部分<img src="C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-07 123635.png" alt="屏幕截图 2025-04-07 123635" style="zoom:75%;" /></p>
<h3 id="发送默认topic消息"><a href="#发送默认topic消息" class="headerlink" title="发送默认topic消息"></a>发送默认topic消息</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sendEvent5</span><span class="params">()</span> &#123;</span><br><span class="line">    kafkaTemplate.sendDefault(<span class="number">0</span>,System.currentTimeMillis(),<span class="string">&quot;key3&quot;</span>,<span class="string">&quot;hello kafka!&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这是参数最全的方法，但是sendDefault方法的所有重载方法都没有指定topic，所以腰要在配置文件中进行配置</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  kafka:</span><br><span class="line">  	template:</span><br><span class="line">  		<span class="keyword">default</span>-topic: <span class="keyword">default</span>-topic</span><br></pre></td></tr></table></figure>

<p>那么就会发送到default-topic</p>
<p>![屏幕截图 2025-04-07 124247](C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-07 124247.png)</p>
<h3 id="send和sendDefaut方法的区别"><a href="#send和sendDefaut方法的区别" class="headerlink" title="send和sendDefaut方法的区别"></a>send和sendDefaut方法的区别</h3><img src="C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-07 124433.png" alt="屏幕截图 2025-04-07 124433" style="zoom: 50%;" />



<h3 id="获取生产者消息发送结果"><a href="#获取生产者消息发送结果" class="headerlink" title="获取生产者消息发送结果"></a>获取生产者消息发送结果</h3><img src="C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-07 124815.png" alt="屏幕截图 2025-04-07 124815" style="zoom: 80%;" />

<p>为什么使用异步编程：</p>
<img src="C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-07 125048.png" alt="屏幕截图 2025-04-07 125048" style="zoom:75%;" />



<h4 id="阻塞式"><a href="#阻塞式" class="headerlink" title="阻塞式"></a>阻塞式</h4><p>使用CompletableFuture的get()方法，同步阻塞等待发送结果</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sendEvent6</span><span class="params">()</span> &#123;</span><br><span class="line">    CompletableFuture&lt;SendResult&lt;String, String&gt;&gt; completableFuture</span><br><span class="line">            = kafkaTemplate.sendDefault(<span class="number">0</span>, System.currentTimeMillis(), <span class="string">&quot;key3&quot;</span>, <span class="string">&quot;hello kafka!&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//通过CompletableFuture这个类拿结果，这个类里面有很多方法</span></span><br><span class="line">    <span class="comment">//1.阻塞等待的方法拿结果</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        SendResult&lt;String, String&gt; sendResult = completableFuture.get();</span><br><span class="line">        <span class="keyword">if</span>(sendResult.getRecordMetadata()!=<span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="comment">//如果以上判断成立（元数据不为空）Kafka服务器接收到了消息</span></span><br><span class="line">            <span class="comment">//以拿topic信息为例</span></span><br><span class="line">            System.out.println(<span class="string">&quot;消息发送成功：&quot;</span>+sendResult.getRecordMetadata().topic());</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;producerRecord：&quot;</span>+sendResult.getProducerRecord());</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="非阻塞式"><a href="#非阻塞式" class="headerlink" title="非阻塞式"></a>非阻塞式</h4><p>使用thenAccept()，thenApply()，thenRun()等方法来注册回调函数，回调函数将在CompletableFuture完成时被执行</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sendEvent7</span><span class="params">()</span> &#123;</span><br><span class="line">    CompletableFuture&lt;SendResult&lt;String, String&gt;&gt; completableFuture</span><br><span class="line">            = kafkaTemplate.sendDefault(<span class="number">0</span>, System.currentTimeMillis(), <span class="string">&quot;key3&quot;</span>, <span class="string">&quot;hello kafka!&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//通过CompletableFuture这个类拿结果，这个类里面有很多方法</span></span><br><span class="line">    <span class="comment">//2.非阻塞的方法拿结果</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">        completableFuture.thenAccept(sendResult-&gt;&#123;</span><br><span class="line">            <span class="keyword">if</span>(sendResult.getRecordMetadata()!=<span class="literal">null</span>) &#123;</span><br><span class="line">                <span class="comment">//如果以上判断成立（元数据不为空）Kafka服务器接收到了消息</span></span><br><span class="line">                <span class="comment">//以拿topic信息为例</span></span><br><span class="line">                System.out.println(<span class="string">&quot;消息发送成功：&quot;</span>+sendResult.getRecordMetadata().topic());</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;producerRecord：&quot;</span>+sendResult.getProducerRecord());</span><br><span class="line">        &#125;)</span><br><span class="line">             .exceptionally(t-&gt;&#123;</span><br><span class="line">                t.printStackTrace();</span><br><span class="line">                <span class="comment">//做消息发送失败处理</span></span><br><span class="line">                 <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="发送对象消息-序列化器"><a href="#发送对象消息-序列化器" class="headerlink" title="*发送对象消息(序列化器)"></a>*发送对象消息(序列化器)</h3><p>在前面的测试中，发的消息都是字符串，下面演示发送对象的操作方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@Builder</span></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> id;</span><br><span class="line">    <span class="keyword">private</span> String phone;</span><br><span class="line">    <span class="keyword">private</span> Date birthday;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sendEvent8</span><span class="params">()</span> &#123;</span><br><span class="line">    User user= User.builder().id(<span class="number">1208</span>).phone(<span class="string">&quot;111111111&quot;</span>).birthday(<span class="keyword">new</span> <span class="title class_">Date</span>()).build();</span><br><span class="line">    <span class="comment">//分区为null，让kafka自己决定把消息发到哪个分区</span></span><br><span class="line">    kafkaTemplate2.sendDefault(<span class="literal">null</span>,System.currentTimeMillis(),<span class="string">&quot;key4&quot;</span>,user);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>但是发现报序列化异常错误，所以加上配置:</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">kafka:</span></span><br><span class="line">  <span class="attr">producer:</span></span><br><span class="line">    <span class="comment">#默认是StringSerializer.class序列化</span></span><br><span class="line">    <span class="attr">value-serializer:</span> <span class="string">org.springframework.kafka.support.serializer.JsonSerializer</span></span><br></pre></td></tr></table></figure>





<h3 id="Replica副本"><a href="#Replica副本" class="headerlink" title="*Replica副本"></a>*Replica副本</h3><p>在 Apache Kafka 中，”replica”（副本）是指分区（Partition）的一个精确复制。Kafka 使用副本机制来提高消息的可靠性和系统的容错能力。每个主题的分区可以有多个副本，其中一个作为领导者（Leader），其余的作为追随者（Follower）。以下是关于 Kafka 副本的一些关键点：</p>
<p>副本的作用</p>
<ol>
<li><strong>数据冗余</strong>：通过在多个 broker 上存储相同的数据副本来防止数据丢失。</li>
<li><strong>高可用性</strong>：如果某个 broker 宕机，其上的分区副本可以在其他 broker 上找到，并且其中的一个副本会被选举为新的领导者，从而保证服务不中断。</li>
<li><strong>负载均衡</strong>：读请求可以被分发到不同的副本上，减轻领导者的负担。</li>
</ol>
<p>相关概念</p>
<ul>
<li><strong>Leader 副本</strong>：每个分区都有一个领导者副本，它负责处理所有的读写请求。</li>
<li><strong>Follower 副本</strong>：除了 Leader 之外的所有副本都是 Follower。它们从 Leader 同步数据，并准备在需要时成为新的 Leader。</li>
<li>**ISR (In-Sync Replicas)**：表示与 Leader 保持同步的副本集合。只有 ISR 集合中的副本才有资格被选举为新的 Leader。</li>
</ul>
<p>注意事项</p>
<ul>
<li><strong>副本的数量不应超过 broker 的数量</strong>：因为副本必须分布在不同的 broker 上，所以 <code>replication.factor</code> 不能大于集群中 broker 的总数。</li>
<li><strong>ISR 与数据一致性</strong>：为了确保数据的一致性，生产者通常会等待 ISR 中的所有副本都确认收到了消息。这可以通过调整生产者的 <code>acks</code> 配置来实现。</li>
</ul>
<p>总结</p>
<p>副本是 Kafka 实现高可用性和数据持久性的核心机制之一。通过合理配置副本因子和了解 ISR 的工作机制，可以有效地提高 Kafka 集群的可靠性和稳定性。对于大多数生产环境来说，推荐至少使用 <code>replication.factor=3</code> 来保证足够的容错能力。</p>
<h4 id="leader副本的分配"><a href="#leader副本的分配" class="headerlink" title="leader副本的分配"></a>leader副本的分配</h4><p>![屏幕截图 2025-04-10 213615](C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-10 213615.png)</p>
<p>一般不建议开启<code>auto.leader.rebalance.enable</code>，如果要开启，建议将不平衡比例阈值增大。</p>
<h3 id="创建topic并指定分区和副本"><a href="#创建topic并指定分区和副本" class="headerlink" title="创建topic并指定分区和副本"></a>创建topic并指定分区和副本</h3><h4 id="命令行"><a href="#命令行" class="headerlink" title="命令行"></a>命令行</h4><p><code>kafka-topics.sh --create --topic my-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 3</code></p>
<p>replica不能超过broker数量，也不能为0（最少为1–自己）</p>
<h4 id="springboot"><a href="#springboot" class="headerlink" title="springboot"></a>springboot</h4><p>在执行代码时指定分区和副本</p>
<p>直接使用send方法发送消息时，如果topic不存在，kafka会帮我们自动完成topic的创建工作，但这种情况下创建的topic默认只有一个分区，分区有一个副本。</p>
<p>我们可以在项目中新建一个配置类专门用来初始化topic</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaConfig</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> NewTopic <span class="title function_">newTopic</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">//名字、partition、副本</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">NewTopic</span>(<span class="string">&quot;He-topic&quot;</span>,<span class="number">5</span>,(<span class="type">short</span>) <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果topic存在(topic名相同)，不会创建（所以重启主程序，不会丢失”He-topic”中的信息）</p>
<p>但是在修改时，虽然也不会弄丢数据，但是分区只能增多不能减少。</p>
<h3 id="生产者发送消息的分区策略-分区器"><a href="#生产者发送消息的分区策略-分区器" class="headerlink" title="生产者发送消息的分区策略(分区器)"></a>生产者发送消息的分区策略(分区器)</h3><p>在发送时，如果不指定放到哪个分区，那么消息放置在哪个分区采用什么策略呢？</p>
<p>据源码分析可知，未指定分区的消息是根据其key使用murmur2哈希算法计算出的分区进行发送的。没有key则采用另外的方法。</p>
<h4 id="RoundRobinPartitioner"><a href="#RoundRobinPartitioner" class="headerlink" title="RoundRobinPartitioner"></a>RoundRobinPartitioner</h4><p>这种分区策略虽然名为轮询，但是并不是严格遵照轮询策略把消息进行分区的。</p>
<p>下面用代码实现使用这种分区策略</p>
<p>在配置类中写入：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Value(&quot;$&#123;spring.kafka.bootstrap-servers&#125;&quot;)</span></span><br><span class="line"><span class="keyword">private</span> String bootstrapServers;</span><br><span class="line"><span class="meta">@Value(&quot;$&#123;spring.kafka.producer.value-serializer&#125;&quot;)</span></span><br><span class="line"><span class="keyword">private</span> String valueSerializer;</span><br><span class="line"><span class="meta">@Value(&quot;$&#123;spring.kafka.producer.key-serializer&#125;&quot;)</span></span><br><span class="line"><span class="keyword">private</span> String keySerializer;</span><br><span class="line"></span><br><span class="line"><span class="comment">//生产者相关配置信息</span></span><br><span class="line"><span class="keyword">public</span> Map&lt;String,Object&gt; <span class="title function_">producerConfigs</span><span class="params">()</span>&#123;</span><br><span class="line">    Map&lt;String, Object&gt; props = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,bootstrapServers);</span><br><span class="line">    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, keySerializer);</span><br><span class="line">    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, valueSerializer);</span><br><span class="line">    props.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, RoundRobinPartitioner.class);</span><br><span class="line">    <span class="keyword">return</span> props;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//生产者工厂</span></span><br><span class="line"><span class="keyword">public</span> ProducerFactory&lt;String,?&gt; producerFactory() &#123;</span><br><span class="line">    <span class="comment">//这里的泛型也是消息的键和值</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">DefaultKafkaProducerFactory</span>&lt;String,Object&gt;(producerConfigs());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//kafkaTemplate 覆盖默认配置类中的kafkaTemplate</span></span><br><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="keyword">public</span> KafkaTemplate&lt;String,?&gt; kafkaTemplate() &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">KafkaTemplate</span>&lt;&gt;(producerFactory());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>用我们自定义的kafkaTemplate覆盖了容器中原有的kafkaTemplate，让它使用RoundRobinPartitioner。</p>
<h4 id="问题待解决-自定义分配策略"><a href="#问题待解决-自定义分配策略" class="headerlink" title="(问题待解决)自定义分配策略"></a>(问题待解决)自定义分配策略</h4><p>自定义XxxPartitioner类继承Partitioner</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomPartitioner</span> <span class="keyword">implements</span> <span class="title class_">Partitioner</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> AtomicInteger nextPartition=<span class="keyword">new</span> <span class="title class_">AtomicInteger</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">partition</span><span class="params">(String topic, Object key, <span class="type">byte</span>[] keyBytes, Object value, <span class="type">byte</span>[] valueBytes, Cluster cluster)</span> &#123;</span><br><span class="line">        <span class="comment">//通过kafka集群信息获取此topic的partitions</span></span><br><span class="line">        List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line">        <span class="type">int</span> <span class="variable">numPartitions</span> <span class="operator">=</span> partitions.size();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(key==<span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="comment">//使用轮询方法选择分区</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">next</span> <span class="operator">=</span> nextPartition.getAndIncrement();</span><br><span class="line">            <span class="keyword">if</span> (next &gt;= numPartitions) &#123;</span><br><span class="line">                nextPartition.compareAndSet(next, <span class="number">0</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;分区值：&quot;</span> + next);</span><br><span class="line">            <span class="keyword">return</span> next;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//如果key不为null，则使用默认的分区策略</span></span><br><span class="line">            <span class="keyword">return</span> Utils.toPositive(Utils.murmur2(keyBytes))%numPartitions;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Map&lt;String, ?&gt; map)</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后再将上一章采用RoundRobinPartitioner的分区策略改成运用我们自定义的分区策略:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">props.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, CustomPartitioner.class);</span><br></pre></td></tr></table></figure>



<p>但是partition方法（计算出要放入的分区的方法）会调用两次，可能达不到我们想要的效果。（待解决）</p>
<h3 id="生产者发送消息的流程"><a href="#生产者发送消息的流程" class="headerlink" title="生产者发送消息的流程"></a>生产者发送消息的流程</h3><img src="C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-07 222551.png" alt="屏幕截图 2025-04-07 222551" style="zoom:75%;" />

<p>其中分区器的方法会执行两次，也就是上一章未解决的问题</p>
<p>简略源码阅读：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV14J4m187jz?p=86&vd_source=c054be8430afebb3d00e5f2d0b77f9fc">https://www.bilibili.com/video/BV14J4m187jz?p=86&amp;vd_source=c054be8430afebb3d00e5f2d0b77f9fc</a></p>
<h3 id="自定义消息发送的拦截器"><a href="#自定义消息发送的拦截器" class="headerlink" title="*自定义消息发送的拦截器"></a>*自定义消息发送的拦截器</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomProducerIntercepter</span> <span class="keyword">implements</span> <span class="title class_">ProducerInterceptor</span>&lt;String,Object&gt; &#123;</span><br><span class="line">    <span class="comment">//发送消息时会先调用该方法，对消息进行拦截</span></span><br><span class="line">    <span class="comment">//可以在拦截中对消息进行一些处理，比如记录日志等操作</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> ProducerRecord&lt;String,Object&gt; <span class="title function_">onSend</span><span class="params">(ProducerRecord producerRecord)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;拦截消息：&quot;</span>+producerRecord.toString());</span><br><span class="line">        <span class="keyword">return</span> producerRecord;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//服务器收到消息后的确认</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onAcknowledgement</span><span class="params">(RecordMetadata recordMetadata, Exception e)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(recordMetadata != <span class="literal">null</span>)&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;服务器收到该消息：&quot;</span>+recordMetadata.offset());</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;消息发送失败:&quot;</span>+e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Map&lt;String, ?&gt; map)</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>给自定义的kafkaTemplate添加拦截器：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG,CustomProducerIntercepter.class.getName());</span><br></pre></td></tr></table></figure>

<h4 id="RecordMetadata"><a href="#RecordMetadata" class="headerlink" title="RecordMetadata"></a>RecordMetadata</h4><p><code>RecordMetadata</code> 是 Kafka 生产者拦截器中一个重要的对象，它记录了消息发送成功后的元数据信息。</p>
<p><strong><code>RecordMetadata</code> 的主要字段</strong></p>
<p><strong>(1) <code>topic()</code></strong></p>
<ul>
<li><strong>含义</strong>：消息被发送到的主题名称。</li>
<li><strong>用途</strong>：用于确认消息被发送到哪个主题。</li>
</ul>
<p><strong>(2) <code>partition()</code></strong></p>
<ul>
<li><strong>含义</strong>：消息被分配到的分区编号。</li>
<li><strong>用途</strong>：用于确认消息被发送到哪个分区。</li>
</ul>
<p><strong>(3) <code>offset()</code></strong></p>
<ul>
<li><strong>含义</strong>：消息在分区中的偏移量（Offset）。</li>
<li>用途<ul>
<li>偏移量是 Kafka 中消息的唯一标识符，表示该消息在分区中的位置。</li>
<li>可以用于追踪消息的位置，或者在消费者端定位消息。</li>
</ul>
</li>
</ul>
<p><strong>(4) <code>timestamp()</code></strong></p>
<ul>
<li><strong>含义</strong>：消息的时间戳。</li>
<li>用途<ul>
<li>如果 Kafka 主题启用了时间戳功能，时间戳可以表示消息的创建时间或日志追加时间。</li>
<li>时间戳对于基于时间的处理（如窗口操作、延迟消息等）非常有用。</li>
</ul>
</li>
</ul>
<p><strong>(5) <code>serializedKeySize()</code> 和 <code>serializedValueSize()</code></strong></p>
<ul>
<li>含义<ul>
<li><code>serializedKeySize()</code>：消息键的序列化大小（以字节为单位）。</li>
<li><code>serializedValueSize()</code>：消息值的序列化大小（以字节为单位）。</li>
</ul>
</li>
<li>用途<ul>
<li>用于监控消息的大小，帮助优化性能或排查问题。</li>
</ul>
</li>
</ul>
<p><strong><code>RecordMetadata</code> 的作用</strong></p>
<p><code>RecordMetadata</code> 提供了关于消息发送结果的详细信息，主要用于以下场景：</p>
<p><strong>(1) 确认消息发送成功</strong></p>
<ul>
<li>当生产者成功将消息发送到 Kafka 集群后，Kafka 会返回 <code>RecordMetadata</code> 对象，表示消息已经成功写入某个分区。</li>
<li>这是生产者确认消息发送成功的标志。</li>
</ul>
<p><strong>(2) 消息追踪</strong></p>
<ul>
<li><code>RecordMetadata</code> 中的 <code>topic</code>、<code>partition</code> 和 <code>offset</code> 信息可以用来唯一标识一条消息。</li>
<li>在分布式系统中，这些信息可以帮助你追踪消息的流向和状态。</li>
</ul>
<p><strong>(3) 性能监控</strong></p>
<ul>
<li><code>serializedKeySize</code> 和 <code>serializedValueSize</code> 可以用来监控消息的大小，帮助识别潜在的性能瓶颈（例如消息过大导致网络传输变慢）。</li>
</ul>
<p><strong>(4) 自定义逻辑</strong></p>
<ul>
<li>在拦截器中，你可以基于<code>RecordMetadata</code>实现自定义逻辑。例如：<ul>
<li>记录消息发送的日志。</li>
<li>统计每个主题或分区的消息发送量。</li>
<li>根据偏移量实现幂等性检查。</li>
</ul>
</li>
</ul>
<p>如果消息发送失败,metadata为null</p>
<h2 id="消费者"><a href="#消费者" class="headerlink" title="消费者"></a>消费者</h2><p>在上面已经简单使用了KafkaListener进行消息的消费</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">EventConsumer</span> &#123;</span><br><span class="line">    <span class="comment">//采用监听的方式接收事件（消息）</span></span><br><span class="line">    <span class="comment">//指定订阅的topic和消费者所在消费者组</span></span><br><span class="line">    <span class="meta">@KafkaListener(topics=&quot;helloTopic&quot;,groupId = &quot;helloGroup&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onEvent</span><span class="params">(<span class="meta">@Payload</span> String message)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;读取到的消息:&quot;</span>+message);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>采用kafkaListener的消费者，其监听的topic如果不存在，在启动项目时会自动创建</p>
<p><code>@Payload</code> 注解可以用来标记一个参数作为从 Kafka 接收到的消息体（即有效负载）的映射目标。这样做的好处是提高了代码的可读性和清晰度，明确指出哪些参数是用来处理消息内容的。</p>
<p>虽然也可以标记在ConsumerRecord参数上，但是最好就标注在消息体对应的参数上。</p>
<h3 id="接收消息"><a href="#接收消息" class="headerlink" title="接收消息"></a>接收消息</h3><h4 id="接收消息头内容"><a href="#接收消息头内容" class="headerlink" title="接收消息头内容"></a>接收消息头内容</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">EventConsumer</span> &#123;</span><br><span class="line">    <span class="comment">//采用监听的方式接收事件（消息）</span></span><br><span class="line">    <span class="comment">//指定订阅的topic和消费者所在消费者组</span></span><br><span class="line">    <span class="meta">@KafkaListener(topics=&quot;helloTopic&quot;,groupId = &quot;helloGroup&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onEvent</span><span class="params">(<span class="meta">@Payload</span> String message,</span></span><br><span class="line"><span class="params">                        <span class="meta">@Header(value= KafkaHeaders.RECEIVED_TOPIC)</span> String topic,</span></span><br><span class="line"><span class="params">                        <span class="meta">@Header(value= KafkaHeaders.RECEIVED_KEY)</span> String key,</span></span><br><span class="line"><span class="params">                        <span class="meta">@Header(value= KafkaHeaders.RECEIVED_PARTITION)</span> String partition)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;读取到的消息:&quot;</span>+message+<span class="string">&quot;,topic:&quot;</span>+topic+<span class="string">&quot;,key:&quot;</span>+key+<span class="string">&quot;,partition:&quot;</span>+partition);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>通过@Header注解获取消息头信息</p>
<h4 id="接收消息所有内容-ConsumerRecord"><a href="#接收消息所有内容-ConsumerRecord" class="headerlink" title="接收消息所有内容(ConsumerRecord)"></a>接收消息所有内容(ConsumerRecord)</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@KafkaListener(topics=&quot;helloTopic&quot;,groupId = &quot;helloGroup&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onEvent</span><span class="params">(ConsumerRecord&lt;Object, Object&gt; record)</span> &#123;</span><br><span class="line">    System.out.println(record.toString());</span><br><span class="line">    System.out.println(record.key()+<span class="string">&quot; &quot;</span>+record.value()+<span class="string">&quot; &quot;</span>+</span><br><span class="line">            record.partition()+<span class="string">&quot; &quot;</span>+record.offset());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="接收对象消息"><a href="#接收对象消息" class="headerlink" title="*接收对象消息"></a>*接收对象消息</h4><p>直接在参数中写User类的参数，无法获得发送的User对象</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">producer:</span></span><br><span class="line">  <span class="attr">value-serializer:</span> <span class="string">org.springframework.kafka.support.serializer.JsonSerializer</span></span><br><span class="line"> </span><br><span class="line"><span class="attr">consumer:</span></span><br><span class="line">  <span class="attr">value-serializer:</span> <span class="string">org.springframework.kafka.support.serializer.JsonDeserializer</span></span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-json<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>



<p>即便这样，还是报错，原因是user不受信任，在序列化、反序列化时出错。</p>
<p>那我们只能采用转化为String再发送的策略</p>
<p>上面两个序列化配置就可以删掉了,但还是要引入依赖</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">JSONUtils</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">ObjectMapper</span> <span class="variable">mapper</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ObjectMapper</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> String <span class="title function_">toJSON</span><span class="params">(Object obj)</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> mapper.writeValueAsString(obj);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (JsonProcessingException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; T <span class="title function_">toBean</span><span class="params">(String json, Class&lt;T&gt; clazz)</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> mapper.readValue(json,clazz);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (JsonProcessingException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sendEvent2</span><span class="params">()</span> &#123;</span><br><span class="line">    User user= <span class="keyword">new</span> <span class="title class_">User</span>();</span><br><span class="line">    user.setBirthday(<span class="keyword">new</span> <span class="title class_">Date</span>());</span><br><span class="line">    user.setId(<span class="number">1208</span>);</span><br><span class="line">    user.setPhone(<span class="string">&quot;111111111&quot;</span>);</span><br><span class="line">    String userJSON= JSONUtils.toJSON(user);</span><br><span class="line">    kafkaTemplate2.send(<span class="string">&quot;helloTopic&quot;</span>,userJSON);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@KafkaListener(topics=&quot;helloTopic&quot;,groupId = &quot;helloGroup&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onEvent</span><span class="params">(String userJSON)</span> &#123;</span><br><span class="line">    User user= JSONUtils.toBean(userJSON, User.class);</span><br><span class="line">    System.out.println(user.toString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="监听器参数引用配置文件的配置"><a href="#监听器参数引用配置文件的配置" class="headerlink" title="监听器参数引用配置文件的配置"></a>监听器参数引用配置文件的配置</h4><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">kafka:</span></span><br><span class="line">    <span class="attr">topic:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">helloTopic</span></span><br><span class="line">    <span class="attr">group:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">helloGroup</span></span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@KafkaListener(topics=&quot;$&#123;spring.kafka.topic.name&#125;&quot;,groupId = &quot;$&#123;spring.kafka.group.name&#125;&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onEvent4</span><span class="params">(String userJSON)</span> &#123;</span><br><span class="line">    User user= JSONUtils.toBean(userJSON, User.class);</span><br><span class="line">    System.out.println(user.toString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="监听器手动确认消息"><a href="#监听器手动确认消息" class="headerlink" title="监听器手动确认消息"></a>监听器手动确认消息</h4><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#开启消息监听的手动确认模式</span></span><br><span class="line"><span class="attr">listener:</span></span><br><span class="line">  <span class="attr">ack-mode:</span> <span class="string">manual</span></span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@KafkaListener(topics=&quot;$&#123;spring.kafka.topic.name&#125;&quot;,groupId = &quot;$&#123;spring.kafka.group.name&#125;&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onEvent4</span><span class="params">(String userJSON,</span></span><br><span class="line"><span class="params">                     Acknowledgment ack)</span> &#123;</span><br><span class="line">    <span class="comment">//收到消息后，处理业务</span></span><br><span class="line">    User user= JSONUtils.toBean(userJSON, User.class);</span><br><span class="line">    System.out.println(user.toString());</span><br><span class="line">    <span class="comment">//业务处理完成，给kafka服务器手动确认</span></span><br><span class="line">    <span class="comment">//手动确认消息，就是告诉kafka服务器，消息已经收到，默认情况下kafka是自动确认</span></span><br><span class="line">    ack.acknowledge();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果开启手动确认模式后，没有进行手动确认，那么就会出现<code>offset</code>未更新的情况，可能会导致消息重复消费。</p>
<p>利用这种性质，我们可以将接收到消息之后的业务处理和确认消息放在try中，如果在消息处理的时候出现异常，将不会确认消息。这样下次还能接收消息并进行业务处理。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">    <span class="meta">@KafkaListener(topics=&quot;$&#123;spring.kafka.topic.name&#125;&quot;,groupId = &quot;$&#123;spring.kafka.group.name&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onEvent4</span><span class="params">(String userJSON,</span></span><br><span class="line"><span class="params">                         Acknowledgment ack)</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//收到消息后，处理业务</span></span><br><span class="line">            User user= JSONUtils.toBean(userJSON, User.class);</span><br><span class="line">            System.out.println(user.toString());</span><br><span class="line">            <span class="comment">//业务处理完成，给kafka服务器手动确认</span></span><br><span class="line">            <span class="comment">//手动确认消息，就是告诉kafka服务器，消息已经收到，默认情况下kafka是自动确认</span></span><br><span class="line">            ack.acknowledge();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="指定topic-partition-offset"><a href="#指定topic-partition-offset" class="headerlink" title="指定topic,partition,offset"></a>指定topic,partition,offset</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@KafkaListener(groupId = &quot;$&#123;spring.kafka.group.name&#125;&quot;,</span></span><br><span class="line"><span class="meta">        topicPartitions = &#123;</span></span><br><span class="line"><span class="meta">                @TopicPartition(</span></span><br><span class="line"><span class="meta">                        topic=&quot;$&#123;spring.kafka.topic.name&#125;&quot;,</span></span><br><span class="line"><span class="meta">                        partitions = &#123;&quot;0&quot;,&quot;1&quot;,&quot;2&quot;&#125;,</span></span><br><span class="line"><span class="meta">                        partitionOffsets = &#123;</span></span><br><span class="line"><span class="meta">                                @PartitionOffset(partition = &quot;3&quot;,initialOffset = &quot;3&quot;),</span></span><br><span class="line"><span class="meta">                                @PartitionOffset(partition = &quot;4&quot;,initialOffset = &quot;3&quot;)</span></span><br><span class="line"><span class="meta">                        &#125;)</span></span><br><span class="line"><span class="meta">        &#125;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onEvent5</span><span class="params">(String userJSON,</span></span><br><span class="line"><span class="params">                     Acknowledgment ack)</span> &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//收到消息后，处理业务</span></span><br><span class="line">        User user= JSONUtils.toBean(userJSON, User.class);</span><br><span class="line">        System.out.println(user.toString());</span><br><span class="line">        <span class="comment">//业务处理完成，给kafka服务器手动确认</span></span><br><span class="line">        <span class="comment">//手动确认消息，就是告诉kafka服务器，消息已经收到，默认情况下kafka是自动确认</span></span><br><span class="line">        ack.acknowledge();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这个注解指定了消费者的组名，并监听这个topic中的0,1,2分区的所有消息，监听3,4分区从offset3开始的消息。</p>
<p>如果先开启监听，再发送消息，012分区能被消费所有的消息，34分区从3开始消费。</p>
<p>如果先发送消息，再开启监听，此时如果没设置auto-offset-reset&#x3D;earlist，那么012不会消费消息，因为默认从最新开始消费。而34分区能消费3offset后的消息。</p>
<p>而这五个分区仍然遵守消息确认就移动该消费者组的offset，offset前的消息该消费者组中的消费者就不再消费了。</p>
<h4 id="批量消费信息"><a href="#批量消费信息" class="headerlink" title="批量消费信息"></a>批量消费信息</h4><ul>
<li><p>设置配置文件开启批量消费</p>
<ul>
<li><p>设置批量消费</p>
<p><code>spring.kafka.listener.type=batch</code></p>
</li>
<li><p>批量消费每次最多消费多少条消息</p>
<p><code>spring.kafka.consumer.max-poll-records=100</code></p>
</li>
</ul>
</li>
<li><p>接收消息时用List来接收</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">EventConsumer</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@KafkaListener(topics = &quot;batchTopic&quot;,groupId = &quot;batchGroup&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onEvent</span><span class="params">(List&lt;ConsumerRecord&lt;String,String&gt;&gt; records)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;批量消费，records=&quot;</span>+records+<span class="string">&quot;size=&quot;</span>+records.size());</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="消息拦截器"><a href="#消息拦截器" class="headerlink" title="*消息拦截器"></a>*消息拦截器</h4><p>在消息消费之前，我们可以通过配置拦截器对消息进行拦截，在消息被实际处理之前对其进行一些操作，例如日志记录、修改消息内容或安全检查。</p>
<p>1.实现kafka的ConsumerInterceptor拦截器接口</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumerInterceptor</span> <span class="keyword">implements</span> <span class="title class_">ConsumerInterceptor</span>&lt;String, String&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//在拿到消息后、消费者拿到消息前执行</span></span><br><span class="line">    <span class="comment">//主要用于对即将返回给消费者的记录进行预处理或修改</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> ConsumerRecords&lt;String, String&gt; <span class="title function_">onConsume</span><span class="params">(ConsumerRecords&lt;String, String&gt; consumerRecords)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;onConsume执行&quot;</span>+consumerRecords);</span><br><span class="line">        <span class="keyword">return</span> consumerRecords;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//在提交偏移量后调用该方法</span></span><br><span class="line">    <span class="comment">//onCommit 方法的作用是用来处理提交后的逻辑，例如记录日志、更新监控指标等。</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCommit</span><span class="params">(Map&lt;TopicPartition, OffsetAndMetadata&gt; map)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;onCommit执行&quot;</span>+map);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span><span class="params">(Map&lt;String, ?&gt; map)</span> &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>2.在kafka消费者的ConsumerFactory配置中注册这个拦截器:</p>
<p><code>props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG,CustomConsumerInterceptor.class.getName())</code></p>
<p>因为spring容器中由默认的consumerFactory和ListenerFactory</p>
<p>这就需要配置一个ConsumerFactory覆盖容器中默认的ConsumerFactory。并向其添加拦截器。</p>
<p>再配置一个自定义的ListenerFactory（需要用到ConsumerFactory），但我们却发现容器中就会出现两个ListenerFactory。解决方法是在@KafkaListener注解中指定ListenerFactory</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">kafka:</span></span><br><span class="line">    <span class="attr">consumer:</span></span><br><span class="line">      <span class="attr">key-deserializer:</span> <span class="string">org.apache.kafka.common.serialization.StringDeserializer</span></span><br><span class="line">      <span class="attr">value-deserializer:</span>  <span class="string">org.apache.kafka.common.serialization.StringDeserializer</span></span><br></pre></td></tr></table></figure>

<p>自定义ConsumerFactory和ListenerFactory：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaConfig</span> &#123;</span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;spring.kafka.bootstrap-servers&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String bootstrapServers;</span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;spring.kafka.consumer.value-deserializer&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String valueSerializer;</span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;spring.kafka.consumer.key-deserializer&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String keySerializer;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//消费者相关配置信息</span></span><br><span class="line">    <span class="keyword">public</span> Map&lt;String,Object&gt; <span class="title function_">consumerConfigs</span><span class="params">()</span>&#123;</span><br><span class="line">        Map&lt;String, Object&gt; props = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,bootstrapServers);</span><br><span class="line">        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, keySerializer);</span><br><span class="line">        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, valueSerializer);</span><br><span class="line">        props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, CustomConsumerInterceptor.class.getName());</span><br><span class="line">        <span class="keyword">return</span> props;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//消费者工厂</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> ConsumerFactory&lt;String,String&gt; <span class="title function_">ourConsumerFactory</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">//这里的泛型也是消息的键和值</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">DefaultKafkaConsumerFactory</span>&lt;&gt;(consumerConfigs());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> KafkaListenerContainerFactory&lt;?&gt; ourKafkaListenerContainerFactory(ConsumerFactory&lt;String,String&gt; ourConsumerFactory) &#123;</span><br><span class="line">        ConcurrentKafkaListenerContainerFactory&lt;String, String&gt; listenerContainerFactory = <span class="keyword">new</span> <span class="title class_">ConcurrentKafkaListenerContainerFactory</span>&lt;&gt;();</span><br><span class="line">        listenerContainerFactory.setConsumerFactory(ourConsumerFactory);</span><br><span class="line">        <span class="keyword">return</span> listenerContainerFactory;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>消费者使用自定义ListenerFactory</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">EventConsumer</span> &#123;</span><br><span class="line">   <span class="meta">@KafkaListener(topics = &quot;interceptorTopic&quot;,groupId = &quot;interceptorGroup&quot;,containerFactory = &quot;ourKafkaListenerContainerFactory&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onEvent</span><span class="params">(ConsumerRecord&lt;String,String&gt; record)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;消息消费&quot;</span>+record);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>测试:</p>
<p>生产者：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">EventProducer</span> &#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> KafkaTemplate&lt;String, Object&gt; kafkaTemplate2;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sendEvent3</span><span class="params">()</span> &#123;</span><br><span class="line">            User user= <span class="keyword">new</span> <span class="title class_">User</span>();</span><br><span class="line">            user.setBirthday(<span class="keyword">new</span> <span class="title class_">Date</span>());</span><br><span class="line">            user.setId(<span class="number">1208</span>);</span><br><span class="line">            user.setPhone(<span class="string">&quot;111111111&quot;</span>);</span><br><span class="line">            String userJSON= JSONUtils.toJSON(user);</span><br><span class="line">            kafkaTemplate2.send(<span class="string">&quot;interceptorTopic&quot;</span>,<span class="string">&quot;key&quot;</span>+i,userJSON);    </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>测试方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootTest</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SpringBoot03KafkaBaseApplicationTests</span> &#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> EventProducer eventProducer;</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="keyword">void</span> <span class="title function_">test01</span><span class="params">()</span> &#123;</span><br><span class="line">        eventProducer.sendEvent3();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="消息转发"><a href="#消息转发" class="headerlink" title="消息转发"></a>消息转发</h4><p>消息转发就是应用A从TopicA收到消息，经过处理后转发到TopicB，再由应用B监听接收该消息，即一个应用处理完成后将该消息转发至其他应用处理，这在实际开发中，是可能存在的</p>
<p>使用@SendTo注解实现</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">EventConsumer</span> &#123;</span><br><span class="line">   <span class="meta">@KafkaListener(topics = &quot;topicA&quot;,groupId = &quot;aGroup&quot;)</span></span><br><span class="line">   <span class="meta">@SendTo(value=&quot;topicB&quot;)</span></span><br><span class="line">   <span class="keyword">public</span> String <span class="title function_">onEventA</span><span class="params">(ConsumerRecord&lt;String,String&gt; record)</span> &#123;</span><br><span class="line">       System.out.println(<span class="string">&quot;A消息消费&quot;</span>+record);</span><br><span class="line">       <span class="keyword">return</span> record.value()+<span class="string">&quot;--forward message&quot;</span>;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@KafkaListener(topics = &quot;topicB&quot;,groupId = &quot;bGroup&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onEventB</span><span class="params">(ConsumerRecord&lt;String,String&gt; record)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;B消息消费&quot;</span>+record);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="消息消费时的分区策略"><a href="#消息消费时的分区策略" class="headerlink" title="消息消费时的分区策略"></a>消息消费时的分区策略</h4><p>指的是Topic中哪些分区由哪些消费者来消费</p>
<p>![屏幕截图 2025-04-08 231659](C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-08 231659.png)</p>
<h5 id="默认分区策略"><a href="#默认分区策略" class="headerlink" title="默认分区策略"></a>默认分区策略</h5><p>![屏幕截图 2025-04-08 234619](C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-08 234619.png)</p>
<p><strong>不同的消费者组之间是相互独立的</strong>，它们会各自独立地消费 Topic 中的所有分区消息。也就是说，一个消费者组内的消费者只会与该组内的其他消费者共享分区，而不会与其他消费者组发生冲突或竞争。</p>
<p>代码演示:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaConfig</span> &#123;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> NewTopic <span class="title function_">newTopic</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">NewTopic</span>(<span class="string">&quot;myTopic&quot;</span>,<span class="number">10</span>,(<span class="type">short</span>) <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">EventConsumer</span> &#123;</span><br><span class="line">    <span class="comment">//concurrency参数代表消费者组中消费者个数,</span></span><br><span class="line">    <span class="meta">@KafkaListener(topics = &quot;myTopic&quot;, groupId = &quot;myGroup3&quot;,concurrency = &quot;3&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onEvent</span><span class="params">(ConsumerRecord&lt;String, String&gt; record)</span> &#123;</span><br><span class="line">        <span class="comment">//这里可以把每个消费者当作一个线程</span></span><br><span class="line">        System.out.println(Thread.currentThread().getId()+<span class="string">&quot;------消费消息-----&quot;</span> + record);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">EventProducer</span> &#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> KafkaTemplate&lt;String, Object&gt; kafkaTemplate2;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">sendEvent3</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">            User user= <span class="keyword">new</span> <span class="title class_">User</span>();</span><br><span class="line">            user.setBirthday(<span class="keyword">new</span> <span class="title class_">Date</span>());</span><br><span class="line">            user.setId(<span class="number">1208</span>);</span><br><span class="line">            user.setPhone(<span class="string">&quot;111111111&quot;</span>);</span><br><span class="line">            String userJSON= JSONUtils.toJSON(user);</span><br><span class="line">            kafkaTemplate2.send(<span class="string">&quot;myTopic&quot;</span>,<span class="string">&quot;key&quot;</span>+i,userJSON);</span><br><span class="line">            <span class="comment">//注意这里key要不同，否则会发到一个分区内</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>经测试上面图片中的方法是正确的。</p>
<h5 id="RoundRobinAssignor"><a href="#RoundRobinAssignor" class="headerlink" title="RoundRobinAssignor"></a>RoundRobinAssignor</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaConfig</span> &#123;</span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;spring.kafka.bootstrap-servers&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String bootstrapServers;</span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;spring.kafka.consumer.value-deserializer&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String valueSerializer;</span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;spring.kafka.consumer.key-deserializer&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String keySerializer;</span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;spring.kafka.consumer.auto-offset-reset&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String autoOffsetReset;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//消费者相关配置信息</span></span><br><span class="line">    <span class="keyword">public</span> Map&lt;String,Object&gt; <span class="title function_">consumerConfigs</span><span class="params">()</span>&#123;</span><br><span class="line">        Map&lt;String, Object&gt; props = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,bootstrapServers);</span><br><span class="line">        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, keySerializer);</span><br><span class="line">        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, valueSerializer);</span><br><span class="line">        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,autoOffsetReset);</span><br><span class="line">        <span class="comment">//指定使用轮询分区器</span></span><br><span class="line">        props.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, RoundRobinAssignor.class.getName());</span><br><span class="line">        <span class="keyword">return</span> props;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//消费者工厂</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> ConsumerFactory&lt;String,String&gt; <span class="title function_">ourConsumerFactory</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">DefaultKafkaConsumerFactory</span>&lt;&gt;(consumerConfigs());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> KafkaListenerContainerFactory&lt;?&gt; ourKafkaListenerContainerFactory(ConsumerFactory&lt;String,String&gt; ourConsumerFactory) &#123;</span><br><span class="line">        ConcurrentKafkaListenerContainerFactory&lt;String, String&gt; listenerContainerFactory = <span class="keyword">new</span> <span class="title class_">ConcurrentKafkaListenerContainerFactory</span>&lt;&gt;();</span><br><span class="line">        listenerContainerFactory.setConsumerFactory(ourConsumerFactory);</span><br><span class="line">        <span class="keyword">return</span> listenerContainerFactory;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> NewTopic <span class="title function_">newTopic</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">NewTopic</span>(<span class="string">&quot;myTopic&quot;</span>,<span class="number">10</span>,(<span class="type">short</span>) <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">EventConsumer</span> &#123;</span><br><span class="line">    <span class="comment">//concurrency参数代表消费者组中消费者个数,并指定自定义的ListenerFactory</span></span><br><span class="line">    <span class="meta">@KafkaListener(topics = &quot;myTopic&quot;, groupId = &quot;myGroup3&quot;,concurrency = &quot;3&quot;,containerFactory = &quot;ourKafkaListenerContainerFactory&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onEvent</span><span class="params">(ConsumerRecord&lt;String, String&gt; record)</span> &#123;</span><br><span class="line">        <span class="comment">//这里可以把每个消费者当作一个线程</span></span><br><span class="line">        System.out.println(Thread.currentThread().getId()+<span class="string">&quot;------消费消息-----&quot;</span> + record);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>经测试，这是完全符合轮询策略的。</p>
<h5 id="两个sticky分区策略"><a href="#两个sticky分区策略" class="headerlink" title="两个sticky分区策略"></a>两个sticky分区策略</h5><img src="C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-09 130150.png" alt="屏幕截图 2025-04-09 130150" style="zoom:75%;" />



<h5 id="建议"><a href="#建议" class="headerlink" title="建议"></a>建议</h5><p>建议使用两个粘性分区策略中的一种</p>
<h3 id="消息的存储"><a href="#消息的存储" class="headerlink" title="消息的存储"></a>消息的存储</h3><img src="C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-09 131157.png" alt="屏幕截图 2025-04-09 131157" style="zoom: 80%;" />

<p>这里我用的是docker启动的，存储的目录需要进入docker容器后，进入&#x2F;tmp&#x2F;kraft-combined-logs文件夹</p>
<h4 id="日志段segment"><a href="#日志段segment" class="headerlink" title="日志段segment"></a>日志段segment</h4><p>Kafka将每个分区的日志（Partition Log）分割成多个较小的文件，这些文件就是所谓的日志段文件。</p>
<ul>
<li>每个分区的日志实际上是由一系列的日志段文件组成的。每当有新的消息被写入Kafka时，这些消息会被追加到当前活跃的日志段文件中。</li>
<li>组成<ul>
<li><strong>.log文件</strong>：包含实际的消息数据。</li>
<li><strong>.index文件</strong>：为.log文件中的消息提供索引，帮助快速定位特定偏移量的消息。</li>
<li><strong>timeindex文件（可选）</strong>：一些版本的Kafka支持基于时间戳的索引，以加速根据时间戳检索消息的过程。</li>
</ul>
</li>
</ul>
<p>日志段管理</p>
<ul>
<li><strong>大小限制</strong>：可以通过配置<code>log.segment.bytes</code>来设置单个日志段的最大大小，默认值通常是1GB。当日志段达到这个大小后，它将被关闭，并创建一个新的日志段用于后续的消息记录。</li>
<li><strong>时间限制</strong>：也可以通过<code>log.roll.ms</code>或<code>log.roll.hours</code>配置项指定基于时间的日志段滚动策略，即使日志段未达到设定的大小，也会根据时间条件进行滚动。</li>
<li><strong>清理策略</strong>：Kafka支持多种日志保留策略，如基于时间和基于大小的策略，用于控制何时删除旧的日志段文件以释放磁盘空间。</li>
</ul>
<p>使用场景和优势</p>
<ul>
<li><strong>提高性能</strong>：通过将日志分成多个小段，可以有效地管理和优化读写操作，特别是在处理大量数据和高吞吐量的情况下。</li>
<li><strong>便于维护</strong>：允许对日志的不同部分执行不同的维护任务，例如压缩、归档或者删除过期的数据。</li>
<li><strong>恢复机制</strong>：在发生故障时，可以根据现有的日志段快速恢复状态，保证系统的可靠性和数据的一致性。</li>
</ul>
<h4 id="consumer-offsets内部主题"><a href="#consumer-offsets内部主题" class="headerlink" title="__consumer_offsets内部主题"></a>__consumer_offsets内部主题</h4><p>刚才的目录中，除了有存储消息相关数据的文件夹，还有<code>__consumer_offsets</code>文件夹。它是自动创建的内部主题<code>__consumer_offsets</code>对应的文件夹。用来存放各消费者组的offset信息。</p>
<p>这个文件夹默认有50个。</p>
<p>每次消费一个消息并提交后，会保存当前消费消息的下一个offset。</p>
<p>消费者提交的offset信息会写入该消费者组对应的__consumer_offsets目录中。</p>
<p>消费者组的offset信息存放在哪个__consumer_offsets文件夹的计算公式：</p>
<p><code>Math.abs(&quot;groupid&quot;.hashCode())%50</code></p>
<p>在idea的kafka插件中打开<code>显示内部主题</code>选项即可显示此内部主题。但是要真正查看文件内容还是要用命令行</p>
<h2 id="offset"><a href="#offset" class="headerlink" title="offset"></a>offset</h2><h3 id="生产者offset"><a href="#生产者offset" class="headerlink" title="生产者offset"></a>生产者offset</h3><p>生产者发送一条消息到kafka的broker的某个topic的某个partition中</p>
<p>kafka内部会为每条消息分配一个唯一的offset，该offset就是该消息在partition中的位置</p>
<p>生产者的offset不用进行设置，由服务器端自动管理</p>
<h3 id="消费者组offset"><a href="#消费者组offset" class="headerlink" title="消费者组offset"></a>消费者组offset</h3><p>每个消费者组会独立的维护自己的offset，当消费者从某个partition读取消息时，它会记录当前读取到的offset。这样即使崩溃或重启，也可以从上次读取的位置继续读取，而不会重复读取或遗漏消息。</p>
<p>消费者消费消息后，如果不提交确认（ack），则offset不更新。</p>
<p>可以通过<code>/opt/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group 组名</code>命令查看消费者组的offset。</p>
<h4 id="自动提交offset"><a href="#自动提交offset" class="headerlink" title="自动提交offset"></a>自动提交offset</h4><p><code>enable.auto.commit</code>：是否开启自动提交功能，默认为true</p>
<p><code>auto.commit.interval.ms</code>：自动提交的间隔(ms)</p>
<h4 id="手动offset"><a href="#手动offset" class="headerlink" title="手动offset"></a>手动offset</h4><img src="C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-10 224132.png" alt="屏幕截图 2025-04-10 224132" style="zoom: 50%;" />



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG,<span class="string">&quot;false&quot;</span>);</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kafkaConsumer.commitSync();</span><br><span class="line">kafkaConsumer.commitAsync();</span><br></pre></td></tr></table></figure>

<h4 id="指定offset"><a href="#指定offset" class="headerlink" title="指定offset"></a>指定offset</h4><p>见 【指定topic、partition、offset】笔记</p>
<h1 id="Kafka集群"><a href="#Kafka集群" class="headerlink" title="Kafka集群"></a>Kafka集群</h1><h2 id="Kafka集群架构"><a href="#Kafka集群架构" class="headerlink" title="Kafka集群架构"></a>Kafka集群架构</h2><img src="C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-09 172613.png" alt="屏幕截图 2025-04-09 172613"  />

<p>副本个数不能为0，也不要能大于broker个数</p>
<p>主副本和从副本不能在同一个broker上，主副本加从副本&#x3D;replica个数</p>
<p>主副本在哪个broker上，是由kafka内部机制决定的</p>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><ul>
<li>broker：kafka服务器</li>
<li>Topic：主题</li>
<li>event：消息（message、事件、数据）</li>
<li>生产者：producer</li>
<li>消费者：consumer</li>
<li>消费者组：consumer group</li>
<li>分区：partition</li>
<li>偏移量：offset</li>
<li>replica：副本（leader replica 和follower replica）</li>
<li>ISR副本（In-Sync Replicas）：</li>
<li>LEO：</li>
<li>HW：</li>
</ul>
<h3 id="ISR副本"><a href="#ISR副本" class="headerlink" title="ISR副本"></a>ISR副本</h3><p>In-Sync Replicas 在同步中的副本，包含了Leader副本和所有与Leader副本保持同步的Follower副本。</p>
<img src="C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-09 181220.png" alt="屏幕截图 2025-04-09 181220" style="zoom:75%;" />

<img src="C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-09 181615.png" alt="屏幕截图 2025-04-09 181615" style="zoom:75%;" />



<h3 id="LEO"><a href="#LEO" class="headerlink" title="LEO"></a>LEO</h3><p>Log End Offset  日志末端偏移量 ，指的是某个副本（无论是主副本还是跟随副本）当前日志末尾的消息偏移量。换句话说，它是该副本上最新写入的消息的下一个位置。LEO 标识了每个副本当前已写入的最大偏移量。也就是说，如果LEO&#x3D;10，那么该副本保存了[0,9]的10条消息。</p>
<h3 id="HW"><a href="#HW" class="headerlink" title="HW"></a>HW</h3><p>High Watermark  高水位值 ,  HW 是所有 <strong>ISR 成员副本中最小的 LEO</strong>。这意味着 HW 表示的是消费者可以安全读取的最大偏移量。只有当 ISR 中的所有副本都确认接收到某条消息时，这条消息的偏移量才会被包含在 HW 中。</p>
<h2 id="基于Kraft搭建kafka集群"><a href="#基于Kraft搭建kafka集群" class="headerlink" title="基于Kraft搭建kafka集群"></a>基于Kraft搭建kafka集群</h2><p>controller节点：<img src="C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-09 192413.png" alt="屏幕截图 2025-04-09 192413" style="zoom: 67%;" /></p>
<ul>
<li><strong>Broker 角色</strong>：处理客户端请求（生产者和消费者的请求），负责存储和管理分区数据。</li>
<li><strong>Controller 角色</strong>：负责管理集群的元数据（如主题、分区、副本分配等），协调分区的领导者选举和故障恢复。</li>
</ul>
<p>zookeeper搭建集群的controller选举方式：<img src="C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-09 192520.png" alt="屏幕截图 2025-04-09 192520" style="zoom:75%;" /></p>
<p>kraft搭建集群的controller选举方式：<img src="C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-09 192528.png" alt="屏幕截图 2025-04-09 192528" style="zoom:80%;" /></p>
<p><strong>kraft建议选举三个controller节点</strong></p>
<h3 id="docker-compose-yml文件"><a href="#docker-compose-yml文件" class="headerlink" title="docker-compose.yml文件"></a>docker-compose.yml文件</h3><p><code>kafka-kraft-cluster</code>目录下创建data目录，创建docker-compose.yml文件</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">kafka1:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">bitnami/kafka:3.7</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">kafka1</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">kafka1</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;19092:9092&quot;</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_KRAFT_CLUSTER_ID=kraft-cluster-id</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_NODE_ID=1</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_PROCESS_ROLES=broker,controller</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka1:9093,2@kafka2:9093,3@kafka3:9093</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_LISTENERS=INTERNAL://:9092,CONTROLLER://:9093</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://192.168.14.128:19092</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_INTER_BROKER_LISTENER_NAME=INTERNAL</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./data/kafka1:/bitnami/kafka</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">kafka-net</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">kafka2:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">bitnami/kafka:3.7</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">kafka2</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">kafka2</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;19093:9092&quot;</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_KRAFT_CLUSTER_ID=kraft-cluster-id</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_NODE_ID=2</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_PROCESS_ROLES=broker,controller</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka1:9093,2@kafka2:9093,3@kafka3:9093</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_LISTENERS=INTERNAL://:9092,CONTROLLER://:9093</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://192.168.14.128:19093</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_INTER_BROKER_LISTENER_NAME=INTERNAL</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./data/kafka2:/bitnami/kafka</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">kafka-net</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">kafka3:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">bitnami/kafka:3.7</span></span><br><span class="line">    <span class="attr">container_name:</span> <span class="string">kafka3</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">kafka3</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;19094:9092&quot;</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_KRAFT_CLUSTER_ID=kraft-cluster-id</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_NODE_ID=3</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_PROCESS_ROLES=broker,controller</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka1:9093,2@kafka2:9093,3@kafka3:9093</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_LISTENERS=INTERNAL://:9092,CONTROLLER://:9093</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://192.168.14.128:19094</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">KAFKA_CFG_INTER_BROKER_LISTENER_NAME=INTERNAL</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">./data/kafka3:/bitnami/kafka</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">kafka-net</span></span><br><span class="line"></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">kafka-net:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">bridge</span></span><br></pre></td></tr></table></figure>

<p>记得要让防护墙开放端口。</p>
<p>远程就可以通过<code>192.168.14.128:19094/192.168.14.128:19093/192.168.14.128:19092</code>连接上kafka集群。</p>
<h1 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h1><h2 id="自定义生产者和消费者"><a href="#自定义生产者和消费者" class="headerlink" title="自定义生产者和消费者"></a>自定义生产者和消费者</h2><p>自定义生产者和消费者能够使我们<strong>更灵活的进行生产者和消费者的配置</strong>。能够满足不同目的（提高性能、减少出错等）</p>
<p>自定义生产者见  【生产者– 自定义消息发送的拦截器】 笔记。</p>
<p>自定义消费者见  【消费者 – 消息拦截器】笔记。</p>
<h2 id="生产者-1"><a href="#生产者-1" class="headerlink" title="生产者"></a>生产者</h2><h3 id="提高生产者吞吐量（数据收集器）"><a href="#提高生产者吞吐量（数据收集器）" class="headerlink" title="提高生产者吞吐量（数据收集器）"></a>提高生产者吞吐量（数据收集器）</h3><p><code>RecordAccumulator</code> 是 Apache Kafka 生产者（Producer）中的一个核心组件，它负责临时存储从应用发送过来的消息，并将这些消息组织成批次（batch），以便更高效地发送到 Kafka 集群。通过这种方式，<code>RecordAccumulator</code> 可以减少网络请求的数量，从而提高生产者的性能和吞吐量。</p>
<ul>
<li><p>当你调用 <code>send()</code> 方法发送一条消息时，这条消息会被序列化并放入 <code>RecordAccumulator</code> 中<strong>对应的主题和分区队列</strong>里。</p>
</li>
<li><p><code>RecordAccumulator</code> 不断检查各个队列中的消息数量和大小。如果某个队列中的消息满足了发送条件（如达到了 <code>batch.size</code> 或者超过了 <code>linger.ms</code> 时间），那么它就会创建一个新的批次并将这些消息加入其中。</p>
</li>
<li><p>一旦批次准备好，<code>RecordAccumulator</code> 会通知 Sender 线程，后者负责将批次发送到对应的 Kafka Broker。</p>
</li>
<li><p>一旦批次成功发送并且收到确认（根据 <code>acks</code> 参数），<code>RecordAccumulator</code> 就会释放这部分内存，以便后续消息可以使用。</p>
</li>
</ul>
<p>![屏幕截图 2025-04-10 163457](C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-10 163457.png)</p>
<p><code>ProducerConfig.BUFFER_MEMORY_CONFIG</code>：缓冲区大小</p>
<p><code>ProducerConfig.BATCH_SIZE_CONFIG</code>：批次大小</p>
<p><code>ProducerConfig.LINGER_MS_CONFIG</code>：linger.ms</p>
<p><code>ProducerConfig.COMPRESSION_TYPE_CONFIG</code>：压缩</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaConfig</span> &#123;</span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;spring.kafka.bootstrap-servers&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String bootstrapServers;</span><br><span class="line">    <span class="comment">//生产者相关配置信息</span></span><br><span class="line">    <span class="keyword">public</span> Map&lt;String,Object&gt; <span class="title function_">producerConfigs</span><span class="params">()</span>&#123;</span><br><span class="line">        Map&lt;String, Object&gt; props = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,bootstrapServers);</span><br><span class="line">        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());</span><br><span class="line">        <span class="comment">//缓冲区大小</span></span><br><span class="line">        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, <span class="number">33554432</span>);</span><br><span class="line">        <span class="comment">//批次大小</span></span><br><span class="line">        props.put(ProducerConfig.BATCH_SIZE_CONFIG, <span class="number">16384</span>);</span><br><span class="line">        <span class="comment">//linger.ms</span></span><br><span class="line">        props.put(ProducerConfig.LINGER_MS_CONFIG, <span class="number">1</span>);</span><br><span class="line">        <span class="comment">//压缩</span></span><br><span class="line">        props.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, <span class="string">&quot;snappy&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> props;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//生产者工厂</span></span><br><span class="line">    <span class="keyword">public</span> ProducerFactory&lt;String,?&gt; producerFactory() &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">DefaultKafkaProducerFactory</span>&lt;String,Object&gt;(producerConfigs());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//kafkaTemplate 覆盖默认配置类中的kafkaTemplate</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> KafkaTemplate&lt;String,?&gt; kafkaTemplate() &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">KafkaTemplate</span>&lt;&gt;(producerFactory());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="Sender线程"><a href="#Sender线程" class="headerlink" title="Sender线程"></a>Sender线程</h3><p>在 Apache Kafka 的生产者（Producer）实现中，<code>Sender</code> 是一个后台线程，负责从 <code>RecordAccumulator</code> 中取出消息批次，并通过网络将它们发送到 Kafka 集群。<code>Sender</code> 线程是确保消息能够高效、可靠地传递到 Kafka Broker 的关键组件之一。</p>
<p>主要职责</p>
<ol>
<li><strong>Metadata 管理</strong>：<ul>
<li><code>Sender</code> 会定期或根据需要更新 Kafka 集群的元数据（如 Broker 列表、主题分区信息等）。这有助于确保消息被发送到正确的 Broker 上。</li>
</ul>
</li>
<li><strong>Batch 获取与发送</strong>：<ul>
<li><code>Sender</code> 线程会从 <code>RecordAccumulator</code> 中获取已经准备好的消息批次（batch），然后将其封装成请求（通常是 Produce 请求），并发送给相应的 Kafka Broker。</li>
</ul>
</li>
<li><strong>网络请求处理</strong>：<ul>
<li>负责建立和维护与 Kafka Broker 的网络连接，并处理各种网络请求和响应。</li>
<li>根据 Broker 的响应结果决定是否需要重试发送失败的消息。</li>
</ul>
</li>
<li><strong>重试机制</strong>：<ul>
<li>当遇到临时性错误时（例如网络超时、Broker 不可用等），<code>Sender</code> 会按照配置的策略进行重试。</li>
</ul>
</li>
<li><strong>关闭逻辑</strong>：<ul>
<li>在关闭 Producer 实例时，<code>Sender</code> 线程需要确保所有待发送的消息都被成功发送出去，并妥善地关闭与 Kafka 集群的所有连接。</li>
</ul>
</li>
</ol>
<p>工作流程</p>
<p>以下是 <code>Sender</code> 线程的工作流程概述：</p>
<ol>
<li>初始化<ul>
<li>当 Kafka 生产者实例启动时，<code>Sender</code> 线程也随之启动，并开始监听来自 <code>RecordAccumulator</code> 的消息批次。</li>
</ul>
</li>
<li>获取 Metadata<ul>
<li>如果需要，<code>Sender</code> 会首先获取最新的集群元数据，以确定每个主题的分区及其对应的 Leader Broker。</li>
</ul>
</li>
<li>构建请求<ul>
<li><code>Sender</code> 线程从 <code>RecordAccumulator</code> 中取出已经准备好发送的消息批次，并为每个批次构建一个 Produce 请求。</li>
</ul>
</li>
<li>发送请求<ul>
<li>将构建好的请求发送给目标 Broker。Kafka 使用高效的二进制协议来序列化这些请求和响应。</li>
</ul>
</li>
<li>处理响应<ul>
<li>接收并解析来自 Broker 的响应。根据响应内容判断消息是否成功发送。如果某个请求失败，则根据配置决定是否重试。</li>
</ul>
</li>
<li>管理连接<ul>
<li>维护与各个 Broker 的连接状态，处理连接建立、断开以及重连等操作。</li>
</ul>
</li>
<li>资源清理<ul>
<li>在 Producer 关闭时，确保所有未完成的消息都已发送，并且所有的网络连接都被正确关闭。</li>
</ul>
</li>
</ol>
<p>相关配置参数</p>
<p>为了优化 <code>Sender</code> 的行为，你可以调整一些相关的配置参数：</p>
<ul>
<li>**<code>retries</code>**：指定当发送失败时尝试重新发送的最大次数。默认值Integer.MAX_VALUE</li>
<li>**<code>retry.backoff.ms</code>**：每次重试之前的等待时间（毫秒）。默认值通常较小，以便快速重试。</li>
<li>**<code>acks</code>**：详见下面的  “数据可靠性”</li>
<li>**<code>connections.max.idle.ms</code>**：设置空闲连接在被关闭前可以保持打开的最大时间。</li>
<li>**<code>request.timeout.ms</code>**：设置等待请求响应的最大时间。如果超过这个时间仍未收到响应，则认为请求失败。</li>
</ul>
<h3 id="数据可靠性（含acks应答）"><a href="#数据可靠性（含acks应答）" class="headerlink" title="数据可靠性（含acks应答）"></a>数据可靠性（含acks应答）</h3><p>在 Apache Kafka 中，<code>acks</code> 是一个关键配置参数，用于控制消息发送的确认机制。它决定了生产者（Producer）在认为一条消息“已发送”之前需要从 Kafka Broker 接收到多少确认。不同的 <code>acks</code> 设置可以在消息可靠性和吞吐量(效率)之间进行权衡。</p>
<p>配置选项：</p>
<p><strong>默认为all</strong></p>
<ol>
<li><strong><code>acks=0</code></strong><ul>
<li><strong>描述</strong>：生产者不会等待任何来自 Broker 的确认。消息一旦被发送出去，就认为发送成功。</li>
<li><strong>优点</strong>：性能最高，因为不需要等待任何响应。</li>
<li><strong>缺点</strong>：最低的消息可靠性。如果发生错误（例如网络故障或 Broker 故障），消息可能会丢失且生产者不会知道。</li>
</ul>
</li>
<li><strong><code>acks=1</code></strong><ul>
<li><strong>描述</strong>：生产者会等待 Leader Broker 的确认。这意味着消息已经被写入 Leader 的日志中，但尚未复制到其他副本。</li>
<li><strong>优点</strong>：提供了一定程度的可靠性，确保至少 Leader 已经接收到消息。</li>
<li><strong>缺点</strong>：如果 Leader 在将消息复制到副本之前失败，则该消息可能会丢失。</li>
</ul>
</li>
<li><strong><code>acks=all</code> 或 <code>acks=-1</code></strong><ul>
<li><strong>描述</strong>：生产者会等待所有同步副本（in-sync replicas, ISR）确认接收了消息。这提供了最高的消息可靠性，因为即使 Leader 发生故障，ISR 中的某个副本也能接管并包含这条消息。</li>
<li><strong>优点</strong>：最高的消息持久性保证，适合对数据丢失零容忍的应用场景。</li>
<li><strong>缺点</strong>：由于需要等待多个副本确认，因此会增加延迟，降低吞吐量。</li>
</ul>
</li>
</ol>
<p>但是，就算设置了acks&#x3D;all也可能有丢数的风险。比如分区副本设置为1，那么此时和acks&#x3D;1效果是一样的。</p>
<p>数据完全可靠条件：</p>
<ul>
<li>ACK级别设置为all</li>
<li>分区副本大于等于2</li>
<li>ISR里应答的最小副本数量大于等于2</li>
</ul>
<p>场景：</p>
<ul>
<li><p>acks&#x3D;0，很少使用</p>
</li>
<li><p>acks&#x3D;1，一般用于普通日志传输，允许丢失个别数据</p>
</li>
<li><p>acks&#x3D;-1，一般用于传输和钱相关的数据，对可靠性要求较高</p>
</li>
<li><p><strong><code>acks</code></strong></p>
</li>
<li><p>**<code>retries</code>**：指定当发送失败时尝试重新发送的最大次数。结合适当的重试策略可以提高消息的成功率。默认值Integer.MAX_VALUE</p>
</li>
<li><p>**<code>retry.backoff.ms</code>**：每次重试之前的等待时间（毫秒）。合理设置这个值可以帮助避免频繁重试导致的资源浪费。</p>
</li>
<li><p>**<code>request.timeout.ms</code>**：设置等待请求响应的最大时间。过长可能导致不必要的延迟，过短则可能引发不必要的重试。</p>
</li>
</ul>
<p>代码演示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">props.put(ProducerConfig.RETRIES_CONFIG,<span class="string">&quot;3&quot;</span>);</span><br><span class="line">props.put(ProducerConfig.ACKS_CONFIG,<span class="string">&quot;1&quot;</span>);</span><br><span class="line">props.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG,<span class="string">&quot;100&quot;</span>);</span><br><span class="line">props.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG,<span class="string">&quot;30000&quot;</span>);</span><br></pre></td></tr></table></figure>



<h3 id="数据重复（含生产者事务）"><a href="#数据重复（含生产者事务）" class="headerlink" title="数据重复（含生产者事务）"></a>数据重复（含生产者事务）</h3><img src="C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-10 185857.png" alt="屏幕截图 2025-04-10 185857" style="zoom: 50%;" />

<p>如何实现精确一次？</p>
<p>–要用到<strong>幂等性和事务</strong>。</p>
<ul>
<li><p>幂等性</p>
<p>幂等性就是Producer不论向Broker发送多少次重复数据，Broker端都只会持久化一条，保证了不重复。</p>
<p><strong>精确一次&#x3D;幂等性+至少一次</strong></p>
<p>重复数据的判断标准:具有&lt;PID,Partition,SeqNumber&gt;相同主键的消息提交时，Broker只会持久化一条。其中PID（producer id）是每次重启都会分配一个新的；Partition是分区号，Sequence Number是单调自增的。</p>
<p>所以幂等性保证的是在<strong>单分区、单会话</strong>内不重复。</p>
</li>
</ul>
<p>​		使用<code>enable.idempotence</code>开启幂等性（默认开启）</p>
<ul>
<li><p>生产者事务</p>
<p><strong>开启事务，必须开启幂等性</strong></p>
<p>虽然 PID 是每次会话事务协调器进行动态分配的，而 TID 是固定的，但 Kafka 使用了一种机制将两者绑定在一起，从而实现了事务的持久性和一致性。以下是具体的工作原理：</p>
<p><strong>(1) 第一次初始化事务</strong></p>
<p>当生产者第一次使用某个 TID 初始化事务时：</p>
<ul>
<li>生产者向 Kafka 集群的事务协调器注册该 TID。</li>
<li>事务协调器为该 TID 分配一个 PID，并将其存储在内部的状态存储中（通常是 Kafka 的内部主题 <code>__transaction_state</code>）。</li>
<li>此后，这个 PID 就与该 TID 绑定在一起。</li>
</ul>
<p><strong>(2) 后续会话中的事务恢复</strong></p>
<p>如果生产者崩溃并重启，或者新的生产者实例使用同一个 TID 初始化事务：</p>
<ul>
<li><p>新的生产者实例会向事务协调器发送请求，提供相同的 TID。</p>
</li>
<li><p>事务协调器会根据 TID 找到之前绑定的 PID，并将该 PID 重新分配给新的生产者实例。</p>
</li>
<li><p>这样，即使生产者实例发生了变化，事务的状态仍然可以通过 TID 和 PID 的绑定关系得以恢复。</p>
<img src="C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-10 191909.png" alt="屏幕截图 2025-04-10 191909" style="zoom:75%;" />

<p>（上图只需要看1-9过程）</p>
</li>
</ul>
</li>
<li><p>代码演示</p>
</li>
</ul>
<p>kafka的事务共5个API：初始化事务、开启事务、在事务内提交已经消费的偏移量（主要用于消费者）、提交事务、放弃事务（类似于回滚事务的操作）</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">props.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG,<span class="string">&quot;t1&quot;</span>);</span><br><span class="line"><span class="type">KafkaProducer</span> <span class="variable">kafkaProducer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(props);</span><br><span class="line">kafkaProducer.initTransactions();</span><br><span class="line">kafkaProducer.beginTransaction();</span><br><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">    <span class="comment">//发送数据</span></span><br><span class="line">    <span class="comment">//....</span></span><br><span class="line">    kafkaProducer.commitTransaction();</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">    kafkaProducer.abortTransaction();</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    kafkaProducer.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="数据有序、InFlightRequests"><a href="#数据有序、InFlightRequests" class="headerlink" title="数据有序、InFlightRequests"></a>数据有序、InFlightRequests</h3><p><code>InFlightRequests</code> 是 Apache Kafka 客户端（包括生产者和消费者）内部用于管理当前正在发送到 Kafka 集群但尚未收到响应的请求的一个概念。这些请求被视为“在飞行中”，它们已经被发送出去，但是客户端还在等待来自 Kafka Broker 的确认或响应。</p>
<p>**<code>max.in.flight.requests.per.connection</code>**表示每个broker上最多有多少消息没有响应。</p>
<p>由于数据发送可能失败，会造成单分区内数据有序性破坏。（比如发送数据12345，但是在发送数据3时发送失败，然后发送4成功，后来发送3成功，这就造成了3和4的乱序）。</p>
<p>为了保证单分区内数据的有序性：<br>kafka1.x版本之前只能设置<code>max.in.flight.requests.per.connection=1</code>（无需考虑幂等性）</p>
<p>kafka1.x版本之后：</p>
<ul>
<li><p>未开启幂等性：</p>
<p>需要设置为1</p>
</li>
<li><p>开启幂等性：</p>
<p>设置小于等于5</p>
<p>因为在启动幂等后，kafka会缓存producer发送来的最近5个request的元数据（按顺序来的可以落盘（存储起来），没按顺序的加入InFlightRequests）。用Sequence Number标记顺序，即使发送失败也会有Sequence Number，直到失败数据重新发送成功使序号能够连续，kafka会将数据按sn排序后落盘。</p>
<p>ifr中有多于5的数据，就不能保证有序了。</p>
</li>
</ul>
<h3 id="Selector"><a href="#Selector" class="headerlink" title="Selector"></a>Selector</h3><p><code>Selector</code> 是一个核心组件，用于处理底层的网络通信。它是基于 Java NIO（非阻塞 I&#x2F;O）实现的一个封装类，负责管理与 Kafka Broker 之间的连接、读写操作以及事件监听。<code>Selector</code> 在 Kafka 客户端（包括生产者和消费者）中扮演着关键角色，是 <code>NetworkClient</code> 的底层依赖。</p>
<p><strong>Selector 的主要职责</strong></p>
<ol>
<li><strong>连接管理</strong>：<ul>
<li><code>Selector</code> 负责建立和维护与 Kafka Broker 的 TCP 连接。</li>
<li>它支持异步连接（非阻塞模式），可以同时处理多个连接。</li>
</ul>
</li>
<li><strong>读写操作</strong>：<ul>
<li><code>Selector</code> 使用 NIO 的 <code>Channel</code> 和 <code>ByteBuffer</code> 来高效地进行数据的读取和写入。</li>
<li>它会将从 Kafka Broker 接收到的数据解码为 Kafka 请求&#x2F;响应对象，并将要发送的数据编码为字节流。</li>
</ul>
</li>
<li><strong>事件监听</strong>：<ul>
<li><code>Selector</code> 监听每个连接上的事件（如可读、可写、连接完成等），并根据事件类型触发相应的操作。</li>
</ul>
</li>
<li><strong>超时管理</strong>：<ul>
<li><code>Selector</code> 支持对连接和请求设置超时时间，确保不会因为某个连接或请求长时间无响应而导致整个客户端阻塞。</li>
</ul>
</li>
<li><strong>多路复用</strong>：<ul>
<li>借助 Java NIO 的 <code>Selector</code>（注意这里的 <code>Selector</code> 是指 Java NIO 的 <code>java.nio.channels.Selector</code>，Kafka 的 <code>Selector</code> 是对其的封装），它可以同时处理多个连接的事件，从而提高并发性能。</li>
</ul>
</li>
</ol>
<p><strong>Selector 的工作流程</strong></p>
<p>以下是 <code>Selector</code> 的典型工作流程：</p>
<ol>
<li><strong>注册连接</strong>：<ul>
<li>当需要与某个 Kafka Broker 建立连接时，<code>Selector</code> 会创建一个 <code>SocketChannel</code> 并将其注册到内部的 NIO <code>Selector</code> 上。</li>
<li>注册时会指定感兴趣的事件类型（如连接完成、可读、可写等）。</li>
</ul>
</li>
<li><strong>事件轮询</strong>：<ul>
<li><code>Selector</code> 使用 Java NIO 的 <code>select()</code> 方法轮询所有注册的连接，检查是否有事件发生。</li>
<li>如果有事件发生（如某个连接可读或可写），<code>Selector</code> 会触发相应的回调函数。</li>
</ul>
</li>
<li><strong>数据读写</strong>：<ul>
<li>对于可写的连接，<code>Selector</code> 会将待发送的数据写入通道。</li>
<li>对于可读的连接，<code>Selector</code> 会从通道中读取数据，并将其传递给上层组件（如 <code>NetworkClient</code>）进行处理。</li>
</ul>
</li>
<li><strong>超时检测</strong>：<ul>
<li><code>Selector</code> 会定期检查每个连接的状态。如果某个连接在指定时间内没有活动，可能会被关闭以释放资源。</li>
</ul>
</li>
<li><strong>断开连接</strong>：<ul>
<li>如果某个连接发生错误（如网络中断），<code>Selector</code> 会将其标记为无效，并通知上层组件进行重连或其他处理。</li>
</ul>
</li>
</ol>
<p><strong>Selector 的实现细节</strong></p>
<p>Kafka 的 <code>Selector</code> 是对 Java NIO 的封装，其内部使用了以下几个关键组件：</p>
<ol>
<li><strong>Java NIO Selector</strong>：<ul>
<li>Kafka 的 <code>Selector</code> 底层依赖于 Java NIO 的 <code>java.nio.channels.Selector</code>，用于多路复用网络连接。</li>
</ul>
</li>
<li><strong>KafkaChannel</strong>：<ul>
<li><code>KafkaChannel</code> 是 Kafka 对 <code>SocketChannel</code> 的封装，提供了更高层次的抽象，便于管理和操作。</li>
</ul>
</li>
<li><strong>Send 和 Receive</strong>：<ul>
<li><code>Send</code> 表示要发送的数据，<code>Receive</code> 表示接收到的数据。它们是对网络数据的封装。</li>
</ul>
</li>
<li><strong>ByteBuffer</strong>：<ul>
<li><code>Selector</code> 使用 <code>ByteBuffer</code> 来存储待发送和接收到的数据。</li>
</ul>
</li>
</ol>
<p><strong>Selector 的优势</strong></p>
<ul>
<li><strong>高性能</strong>：通过使用 Java NIO，<code>Selector</code> 能够高效地处理多个连接，避免了传统阻塞 I&#x2F;O 的线程开销。</li>
<li><strong>低延迟</strong>：由于是非阻塞模式，<code>Selector</code> 可以快速响应网络事件，减少延迟。</li>
<li><strong>灵活性</strong>：支持动态添加和移除连接，能够适应 Kafka 集群的动态变化。</li>
</ul>
<p><strong>Selector 的配置参数</strong></p>
<p>以下是一些与 <code>Selector</code> 相关的配置参数：</p>
<ol>
<li>**<code>connections.max.idle.ms</code>**：<ul>
<li>设置空闲连接在被关闭前可以保持打开的最大时间。</li>
</ul>
</li>
<li>**<code>reconnect.backoff.ms</code> 和 <code>reconnect.backoff.max.ms</code>**：<ul>
<li>控制重新连接尝试之间的等待时间和最大等待时间。</li>
</ul>
</li>
<li>**<code>request.timeout.ms</code>**：<ul>
<li>设置等待请求响应的最大时间。</li>
</ul>
</li>
<li>**<code>socket.connection.setup.timeout.ms</code>**：<ul>
<li>设置建立连接的超时时间。</li>
</ul>
</li>
</ol>
<h2 id="高效读写数据"><a href="#高效读写数据" class="headerlink" title="*高效读写数据"></a>*高效读写数据</h2><img src="C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-10 214741.png" alt="屏幕截图 2025-04-10 214741" style="zoom:75%;" />

<p>采用零拷贝(sendfile):</p>
<p>非零拷贝（Traditional I&#x2F;O）</p>
<p>传统的文件读取或网络传输操作通常涉及多次数据复制。以从磁盘读取文件并通过网络发送为例，这个过程可能包括以下步骤：</p>
<ol>
<li><strong>从磁盘读取数据到内核空间缓冲区</strong>。</li>
<li><strong>将数据从内核空间复制到用户空间缓冲区</strong>（应用程序层面）。</li>
<li><strong>处理数据</strong>（例如，打包成网络包）。</li>
<li><strong>将处理后的数据再次从用户空间复制回内核空间</strong>，这次是为网络接口准备的。</li>
<li><strong>通过网络接口发送数据</strong>，这可能还需要额外的数据复制。</li>
</ol>
<p>这种模式下，每次数据都需要经过多次复制才能最终到达目的地，这就是所谓的“非零拷贝”。</p>
<p>零拷贝（Zero-Copy）</p>
<p>零拷贝技术旨在减少或者完全消除上述过程中不必要的数据复制，从而提高效率、降低延迟并减少 CPU 使用率。在实现零拷贝时，目标是从磁盘直接读取数据到网卡，而无需经过用户空间的应用程序。</p>
<p>Kafka 实现了部分零拷贝功能，主要是通过利用操作系统提供的支持来实现这一点，如 Linux 上的 <code>sendfile()</code> 系统调用。<code>sendfile()</code> 允许服务器上的一个文件直接传输给客户端，而不需要先将文件内容加载到应用层再发送出去。</p>
<p>在 Kafka 中的应用</p>
<ul>
<li><strong>文件通道传输</strong>：当消费者拉取消息时，如果消息存储在磁盘上，Kafka 可以使用 Java NIO 的 FileChannel.transferTo 方法，该方法底层会调用操作系统的 <code>sendfile()</code>，从而避免了数据在内核态和用户态之间的来回拷贝。</li>
<li><strong>减少内存占用</strong>：通过零拷贝，可以显著减少内存占用，因为数据不必在多个地方被重复存储。</li>
<li><strong>提升性能</strong>：减少了CPU参与数据复制的过程，使得整个系统更加高效。</li>
</ul>
<p>然而，需要注意的是，虽然 Kafka 支持零拷贝特性，但它并不能完全消除所有场景下的数据复制。例如，在某些情况下，比如需要对消息进行压缩或解压缩时，仍然不可避免地会有额外的数据处理步骤，这些步骤可能会引入新的数据复制。</p>
<h2 id="消费者-1"><a href="#消费者-1" class="headerlink" title="消费者"></a>消费者</h2><h3 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h3><p>一个消费者可以消费多个分区的数据，一个消费者组不允许出现两个消费者消费同一个分区的情况。</p>
<p><strong>一个消费者不能同时属于多个消费者组</strong>。</p>
<h3 id="消费者组消费流程"><a href="#消费者组消费流程" class="headerlink" title="消费者组消费流程"></a>消费者组消费流程</h3><p>![屏幕截图 2025-04-10 222733](C:\Users\14693\Desktop\Screenshots\屏幕截图 2025-04-10 222733.png)</p>
<h3 id="按指定时间消费"><a href="#按指定时间消费" class="headerlink" title="按指定时间消费"></a>按指定时间消费</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.Consumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.OffsetAndTimestamp;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.TopicPartition;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.core.DefaultKafkaConsumerFactory;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.core.KafkaTemplate;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.listener.ContainerProperties;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.listener.KafkaMessageListenerContainer;</span><br><span class="line"><span class="keyword">import</span> org.springframework.kafka.listener.MessageListener;</span><br><span class="line"><span class="keyword">import</span> org.springframework.stereotype.Service;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.time.Instant;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaManualOffsetService</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> DefaultKafkaConsumerFactory&lt;String, String&gt; consumerFactory;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">KafkaManualOffsetService</span><span class="params">(DefaultKafkaConsumerFactory&lt;String, String&gt; consumerFactory)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.consumerFactory = consumerFactory;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">startConsumingFromTime</span><span class="params">(String topic, Instant startTime)</span> &#123;</span><br><span class="line">        Map&lt;String, Object&gt; configs = consumerFactory.getConfigurationProperties();</span><br><span class="line">        <span class="keyword">try</span> (Consumer&lt;String, String&gt; consumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(configs)) &#123;</span><br><span class="line">            consumer.subscribe(Collections.singletonList(topic));</span><br><span class="line">            <span class="comment">// 获取分区信息</span></span><br><span class="line">            List&lt;PartitionInfo&gt; partitions = consumer.partitionsFor(topic);</span><br><span class="line">            Map&lt;TopicPartition, Long&gt; timestampsToSearch = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">            <span class="keyword">for</span> (PartitionInfo partition : partitions) &#123;</span><br><span class="line">                timestampsToSearch.put(<span class="keyword">new</span> <span class="title class_">TopicPartition</span>(partition.topic(), partition.partition()), startTime.toEpochMilli());</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 根据时间戳获取偏移量</span></span><br><span class="line">            Map&lt;TopicPartition, OffsetAndTimestamp&gt; offsets = consumer.offsetsForTimes(timestampsToSearch);</span><br><span class="line">            <span class="comment">// 设置消费者偏移量</span></span><br><span class="line">            offsets.forEach((tp, offsetAndTimestamp) -&gt; &#123;</span><br><span class="line">                <span class="keyword">if</span> (offsetAndTimestamp != <span class="literal">null</span>) &#123;</span><br><span class="line">                    <span class="comment">//将消费者分配到指定的分区（tp）。Kafka 消费者可以手动分配分区而不是通过订阅主题（subscribe）。</span></span><br><span class="line">					<span class="comment">//Collections.singletonList(tp) 表示只分配一个分区。</span></span><br><span class="line">                    consumer.assign(Collections.singletonList(tp));</span><br><span class="line">                    <span class="comment">//将消费者的偏移量设置到指定位置（offsetAndTimestamp.offset()）。</span></span><br><span class="line">                    consumer.seek(tp, offsetAndTimestamp.offset());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 开始监听消息</span></span><br><span class="line">            <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">                <span class="comment">//poll 是 Kafka 消费者的拉取消息方法。它会向 Kafka Broker 发起请求，获取当前分配给消费者的分区中的可用消息。如果没有新消息，poll 方法会阻塞一段时间（由参数决定）后返回一个空的结果。</span></span><br><span class="line">                <span class="type">var</span> <span class="variable">records</span> <span class="operator">=</span> consumer.poll(Duration.ofMillis(<span class="number">100</span>));</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">var</span> record : records) &#123;</span><br><span class="line">                    System.out.printf(<span class="string">&quot;Consumed message: key = %s, value = %s, partition = %d, offset = %d%n&quot;</span>,</span><br><span class="line">                            record.key(), record.value(), record.partition(), record.offset());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="消费者事务"><a href="#消费者事务" class="headerlink" title="消费者事务"></a>消费者事务</h3><p>在 Kafka 中，消费者事务的概念与生产者的事务机制有所不同。Kafka 的事务主要设计用于生产者端，以确保消息的原子性写入（即要么所有消息都成功写入，要么都不写入）。然而，对于消费者来说，Kafka 提供了一些机制来支持“幂等性”消费和确保消息被正确处理，但并不直接支持像生产者那样的事务管理。</p>
<p>不过，Kafka 消费者可以通过一些特定的方式实现类似事务的效果，确保消息的精确一次处理（exactly-once semantics, EOS）。下面介绍如何在消费者端实现这种效果：</p>
<p>实现精确一次处理</p>
<p>为了实现精确一次处理，通常需要结合 Kafka 的以下特性：</p>
<ol>
<li><strong>幂等性和事务（Idempotence and Transactions）</strong>：虽然这主要是针对生产者的，但是它也是消费者EOS的一部分，因为消费者需要能够正确处理已经被事务性地写入的消息。</li>
<li><strong>偏移量提交控制（Offset Commit Control）</strong>：通过手动管理偏移量的提交，可以确保只有当消息被成功处理后，才会提交对应的偏移量。这样即使处理过程中出现故障，也不会丢失或重复处理消息。</li>
<li>**Exactly-Once Semantics (EOS)**：从 Kafka 0.11.0 版本开始，Kafka 支持精确一次语义。这包括了对生产者端的支持以及允许消费者在读取时配合使用事务来达到EOS。</li>
</ol>
<p>在 Spring Kafka 中启用精确一次处理</p>
<p>要在 Spring Kafka 中启用精确一次处理，你可以采取如下步骤：</p>
<ol>
<li>配置消费者的自动偏移量提交为 <code>false</code></li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spring.kafka.consumer.enable-auto-commit=<span class="literal">false</span></span><br></pre></td></tr></table></figure>

<p>这意味着你需要手动管理偏移量的提交，以便更好地控制何时确认消息已被成功处理。</p>
<ol start="2">
<li>使用 <code>AckMode</code> 来手动提交偏移量</li>
</ol>
<p>Spring Kafka 提供了几种不同的 <code>AckMode</code> 来控制偏移量的提交时机。例如，使用 <code>MANUAL_IMMEDIATE</code> 模式可以让开发者在代码中明确指出何时提交偏移量。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line"><span class="keyword">public</span> ConcurrentKafkaListenerContainerFactory&lt;String, String&gt; <span class="title function_">kafkaListenerContainerFactory</span><span class="params">(</span></span><br><span class="line"><span class="params">        ConsumerFactory&lt;String, String&gt; consumerFactory)</span> &#123;</span><br><span class="line">    ConcurrentKafkaListenerContainerFactory&lt;String, String&gt; factory =</span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">ConcurrentKafkaListenerContainerFactory</span>&lt;&gt;();</span><br><span class="line">    factory.setConsumerFactory(consumerFactory);</span><br><span class="line">    factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL_IMMEDIATE);</span><br><span class="line">    <span class="keyword">return</span> factory;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后，在你的监听器方法中，你可以根据业务逻辑的结果决定是否提交偏移量：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@KafkaListener(topics = &quot;myTopic&quot;, groupId = &quot;myGroup&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">listen</span><span class="params">(ConsumerRecord&lt;String, String&gt; record, Acknowledgment ack)</span> &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 处理消息</span></span><br><span class="line">        processMessage(record.value());</span><br><span class="line">        <span class="comment">// 如果处理成功，则提交偏移量</span></span><br><span class="line">        ack.acknowledge();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="comment">// 如果处理失败，则不提交偏移量，从而允许重新消费该消息</span></span><br><span class="line">        log.error(<span class="string">&quot;Failed to process message: &#123;&#125;&quot;</span>, record, e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="数据积压"><a href="#数据积压" class="headerlink" title="数据积压"></a>数据积压</h3><p>数据积压（也称为滞后或lag）是指消费者组处理消息的速度跟不上生产者生成消息的速度，导致未消费的消息数量增加。这种情况可能会导致延迟增加，甚至影响到系统的实时性要求。</p>
<p>当发现数据积压时，可能的原因包括但不限于：</p>
<ul>
<li><strong>消费者处理速度慢</strong>：可能是由于消费者端逻辑复杂或者资源限制（如CPU、内存不足）导致处理效率低下。</li>
<li><strong>网络问题</strong>：网络延迟可能导致消费者接收消息变慢。</li>
<li><strong>Kafka 集群负载高</strong>：如果 Kafka 集群本身处于高负载状态，也可能影响消息的传输速率。</li>
<li><strong>不合理的配置</strong>：例如，<code>fetch.max.bytes</code>, <code>max.poll.records</code> 等参数设置不当，可能导致每次拉取的数据量过大或过小，影响消费速度。</li>
</ul>
<p>针对不同的原因，可以采取相应的措施：</p>
<ol>
<li><strong>优化消费者逻辑</strong>：<ul>
<li>检查并优化消费者端代码，减少不必要的计算和I&#x2F;O操作。</li>
<li>增加并发度，比如通过增加消费者实例数（确保不超过分区总数），利用多线程提高处理能力。</li>
</ul>
</li>
<li><strong>调整 Kafka 配置</strong>：<ul>
<li>调整 <code>fetch.min.bytes</code>, <code>fetch.max.wait.ms</code>, <code>max.poll.records</code> 等参数，平衡单次请求获取的消息数量和等待时间。</li>
<li>对于大消息场景，适当增大 <code>fetch.max.bytes</code> 和 <code>replica.fetch.max.bytes</code> 的值。</li>
</ul>
</li>
<li><strong>扩展 Kafka 集群</strong>：<ul>
<li>如果集群整体负载过高，考虑增加 Broker 数量或分区数量，分散负载。</li>
</ul>
</li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://mutesniper.github.io">Muite</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://mutesniper.github.io/2025/04/11/Kafka/">https://mutesniper.github.io/2025/04/11/Kafka/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/JAVA/">JAVA</a><a class="post-meta__tags" href="/tags/note/">note</a></div><div class="post-share"><div class="social-share" data-image="https://img.alicdn.com/bao/uploaded/i3/2200690044395/O1CN012NL22Q1iKxHYWb17f_!!2200690044395.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related full-width" href="/2025/04/06/MyBatisPlus/" title="JAVA学习笔记-MyBatisPlus"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">JAVA学习笔记-MyBatisPlus</div></div><div class="info-2"><div class="info-item-1">入门使用MybatisPlus的基本步骤 引入MybatisPls依赖，代替Mybatis依赖 12345&lt;dependency&gt;    &lt;groupId&gt;com.baomidou&lt;/groupId&gt;    &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;    &lt;version&gt;3.5.3.1&lt;/version&gt;&lt;/dependency&gt;  定义Mapper接口并继承BaseMapper 12public interface UserMapper extends...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/03/17/List/" title="JAVA学习笔记-集合(待更新)"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-17</div><div class="info-item-2">JAVA学习笔记-集合(待更新)</div></div><div class="info-2"><div class="info-item-1">ArrayList 数组可以存储基本数据类型和引用数据类型，集合只能存储引用数据类型，如果要存储基本数据类型，必须要打包成包装类次啊能存储。  成员方法 添加元素，返回值表示是否添加成功  1boolean add(E e)   删除指定元素,返回值表示是否删除成功  1boolean remove(E e)   删除指定索引的元素,返回被删除的元素  1E remove(int index)   修改指定索引下的元素,返回原来的元素  1E set(int index,E e)   获取指定索引的元素  1E get(int index)   返回集合的长度  1int size()    LinkedList 底层数据结构是双向链表。这使LinkedList的查询慢、增删快。但如果查询的是首尾元素也很快  LinkedList特有的API（用到很少，主要还是collection和list中的方法）  在该列表开头插入指定元素  1public void addFirst(E e)     将指定的元素追加到此列表的末尾  1public void addLast(E...</div></div></div></a><a class="pagination-related" href="/2025/03/17/String/" title="JAVA学习笔记-String"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-17</div><div class="info-item-2">JAVA学习笔记-String</div></div><div class="info-2"><div class="info-item-1">String:特性： 内容不会发生改变，它的对象在创建后不能被更改。如果进行修改则会创建一个新的字符串变量。 由于String对象不可变，所以它是线程安全的。  创建方法： 直接赋值： 1String name=&quot;... &quot;;  构造方法： 1234public String()public String(String original)public String(char[] chs)public String (byte[] chs)  方法： 获取长度：1str.length() 查找子串:1234//返回第一个指定字串的索引str.indexOf...</div></div></div></a><a class="pagination-related" href="/2025/03/17/MyBatis/" title="JAVA学习笔记-MyBatis"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-17</div><div class="info-item-2">JAVA学习笔记-MyBatis</div></div><div class="info-2"><div class="info-item-1">简介MyBatis是持久层框架（和数据库进行交互的框架） MyBatis 不像 Hibernete 等这些全自动框架，它把关键的SQL部分交给程序员自己编写，而不是自动生成  HelloWorld步骤：  导入mybatis依赖  配置数据源  编写javabean对应数据库一个表模型  以前：Dao接口–&gt;Dao实现  。–&gt;标注@Repository注解 现在：Mapper接口–&gt;Mapper.xml实现 ,–&gt;标注@Mapper注解 （安装mybatisx插件自动为mapper类生成mapper文件，我们只需要在mapper文件中配置方法的sql语句）  告诉mybatis去哪里找mapper文件：mybatis.mapper-locations=classpath:mapper/**.xml   mapper接口： 1234@Mapper //告诉spring，这是MyBatis操作数据库用的接口public interface EmpMapper &#123;    Emp getEmpById(Integer...</div></div></div></a><a class="pagination-related" href="/2025/03/17/maven%E5%9F%BA%E7%A1%80/" title="JAVA学习笔记-maven基础"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-17</div><div class="info-item-2">JAVA学习笔记-maven基础</div></div><div class="info-2"><div class="info-item-1">简介在了解Maven之前，我们先来看看一个Java项目需要的东西。首先，我们需要确定引入哪些依赖包。例如，如果我们需要用到commons logging，我们就必须把commons...</div></div></div></a><a class="pagination-related" href="/2025/03/17/springboot/" title="JAVA学习笔记-springBoot"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-17</div><div class="info-item-2">JAVA学习笔记-springBoot</div></div><div class="info-2"><div class="info-item-1">简介SpringBoot 帮我们简单、快速地创建一个独立的、生产级别的 Spring 应用； 特性：  快速创建独立 Spring 应用  直接嵌入Tomcat、Jetty or Undertow  提供可选的 starter，简化应用整合  按需自动配置 Spring 以及 第三方库  提供生产级特性：如 监控指标、健康检查、外部化配置等  无代码生成、无xml； 都是基于自动配置技术   场景启动器SpringBoot场景启动器：官方写的启动器命名：spring-boot-starter-*。第三方启动器命名：*-spring-boot-starter ​	作用：场景启动器负责把当前场景需要用的jar包都导入进来 ​	每个场景启动器都有一个基础依赖：spring-boot-starter 依赖管理为什么项目依赖不需要写版本号？—maven父子继承，父项目可以锁定版本。 父项目不管理的包都需要添加版本号 *自动配置基本理解 自动配置 导入场景，容器中就会自动配置好这个场景的核心组件。如 Tomcat、SpringMVC、DataSource...</div></div></div></a><a class="pagination-related" href="/2025/03/17/spring/" title="JAVA学习笔记-spring"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-17</div><div class="info-item-2">JAVA学习笔记-spring</div></div><div class="info-2"><div class="info-item-1">简介spring是一个IoC和AOP框架 Spring的特性：  非侵入式：基于Spring开发的应用中的对象可以不依赖于Spring的API 依赖注入：DI（Dependency Injection）是反转控制（IoC：Inversion of Control）最经典的实现 面向切面编程：Aspect Oriented Programming ...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="https://img.alicdn.com/bao/uploaded/i3/2200690044395/O1CN012NL22Q1iKxHYWb17f_!!2200690044395.jpg" onerror="this.onerror=null;this.src='/null'" alt="avatar"/></div><div class="author-info-name">Muite</div><div class="author-info-description">keep learning</div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">17</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/mutesniper"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/mutesniper" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E5%90%AF%E5%8A%A8Kafka"><span class="toc-number">1.</span> <span class="toc-text">运行启动Kafka</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%A5%E4%B8%8B%E5%9D%87%E5%9F%BA%E4%BA%8Ekraft%E5%90%AF%E5%8A%A8"><span class="toc-number">2.</span> <span class="toc-text">以下均基于kraft启动</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A4%96%E9%83%A8%E8%BF%9E%E6%8E%A5kafka"><span class="toc-number">3.</span> <span class="toc-text">外部连接kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%87%E4%BB%B6%E8%A6%86%E7%9B%96%EF%BC%9A"><span class="toc-number">3.0.1.</span> <span class="toc-text">文件覆盖：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Springboot%E9%9B%86%E6%88%90kafka"><span class="toc-number">4.</span> <span class="toc-text">Springboot集成kafka</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85"><span class="toc-number">4.1.</span> <span class="toc-text">生产者</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Kaka%E5%87%A0%E4%B8%AA%E6%A6%82%E5%BF%B5"><span class="toc-number">4.1.1.</span> <span class="toc-text">*Kaka几个概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Event%E7%94%9F%E4%BA%A7"><span class="toc-number">4.1.2.</span> <span class="toc-text">Event生产</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Event%E6%B6%88%E8%B4%B9"><span class="toc-number">4.1.3.</span> <span class="toc-text">Event消费</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E6%97%B6%E5%81%8F%E7%A7%BB%E9%87%8F%E7%AD%96%E7%95%A5%E7%9A%84%E9%85%8D%E7%BD%AE"><span class="toc-number">4.1.3.1.</span> <span class="toc-text">消费时偏移量策略的配置</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%91%E9%80%81Message%E5%AF%B9%E8%B1%A1%E6%B6%88%E6%81%AF"><span class="toc-number">4.1.4.</span> <span class="toc-text">发送Message对象消息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%91%E9%80%81ProducerRecord%E5%AF%B9%E8%B1%A1%E6%B6%88%E6%81%AF"><span class="toc-number">4.1.5.</span> <span class="toc-text">发送ProducerRecord对象消息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%91%E9%80%81%E6%8C%87%E5%AE%9A%E5%88%86%E5%8C%BA%E7%9A%84%E6%B6%88%E6%81%AF"><span class="toc-number">4.1.6.</span> <span class="toc-text">发送指定分区的消息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%91%E9%80%81%E9%BB%98%E8%AE%A4topic%E6%B6%88%E6%81%AF"><span class="toc-number">4.1.7.</span> <span class="toc-text">发送默认topic消息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#send%E5%92%8CsendDefaut%E6%96%B9%E6%B3%95%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">4.1.8.</span> <span class="toc-text">send和sendDefaut方法的区别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8E%B7%E5%8F%96%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E7%BB%93%E6%9E%9C"><span class="toc-number">4.1.9.</span> <span class="toc-text">获取生产者消息发送结果</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%98%BB%E5%A1%9E%E5%BC%8F"><span class="toc-number">4.1.9.1.</span> <span class="toc-text">阻塞式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9D%9E%E9%98%BB%E5%A1%9E%E5%BC%8F"><span class="toc-number">4.1.9.2.</span> <span class="toc-text">非阻塞式</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%91%E9%80%81%E5%AF%B9%E8%B1%A1%E6%B6%88%E6%81%AF-%E5%BA%8F%E5%88%97%E5%8C%96%E5%99%A8"><span class="toc-number">4.1.10.</span> <span class="toc-text">*发送对象消息(序列化器)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Replica%E5%89%AF%E6%9C%AC"><span class="toc-number">4.1.11.</span> <span class="toc-text">*Replica副本</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#leader%E5%89%AF%E6%9C%AC%E7%9A%84%E5%88%86%E9%85%8D"><span class="toc-number">4.1.11.1.</span> <span class="toc-text">leader副本的分配</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BAtopic%E5%B9%B6%E6%8C%87%E5%AE%9A%E5%88%86%E5%8C%BA%E5%92%8C%E5%89%AF%E6%9C%AC"><span class="toc-number">4.1.12.</span> <span class="toc-text">创建topic并指定分区和副本</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%91%BD%E4%BB%A4%E8%A1%8C"><span class="toc-number">4.1.12.1.</span> <span class="toc-text">命令行</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#springboot"><span class="toc-number">4.1.12.2.</span> <span class="toc-text">springboot</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5-%E5%88%86%E5%8C%BA%E5%99%A8"><span class="toc-number">4.1.13.</span> <span class="toc-text">生产者发送消息的分区策略(分区器)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RoundRobinPartitioner"><span class="toc-number">4.1.13.1.</span> <span class="toc-text">RoundRobinPartitioner</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E5%BE%85%E8%A7%A3%E5%86%B3-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="toc-number">4.1.13.2.</span> <span class="toc-text">(问题待解决)自定义分配策略</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E7%9A%84%E6%B5%81%E7%A8%8B"><span class="toc-number">4.1.14.</span> <span class="toc-text">生产者发送消息的流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E7%9A%84%E6%8B%A6%E6%88%AA%E5%99%A8"><span class="toc-number">4.1.15.</span> <span class="toc-text">*自定义消息发送的拦截器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RecordMetadata"><span class="toc-number">4.1.15.1.</span> <span class="toc-text">RecordMetadata</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85"><span class="toc-number">4.2.</span> <span class="toc-text">消费者</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A5%E6%94%B6%E6%B6%88%E6%81%AF"><span class="toc-number">4.2.1.</span> <span class="toc-text">接收消息</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8E%A5%E6%94%B6%E6%B6%88%E6%81%AF%E5%A4%B4%E5%86%85%E5%AE%B9"><span class="toc-number">4.2.1.1.</span> <span class="toc-text">接收消息头内容</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8E%A5%E6%94%B6%E6%B6%88%E6%81%AF%E6%89%80%E6%9C%89%E5%86%85%E5%AE%B9-ConsumerRecord"><span class="toc-number">4.2.1.2.</span> <span class="toc-text">接收消息所有内容(ConsumerRecord)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8E%A5%E6%94%B6%E5%AF%B9%E8%B1%A1%E6%B6%88%E6%81%AF"><span class="toc-number">4.2.1.3.</span> <span class="toc-text">*接收对象消息</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%91%E5%90%AC%E5%99%A8%E5%8F%82%E6%95%B0%E5%BC%95%E7%94%A8%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%9A%84%E9%85%8D%E7%BD%AE"><span class="toc-number">4.2.1.4.</span> <span class="toc-text">监听器参数引用配置文件的配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9B%91%E5%90%AC%E5%99%A8%E6%89%8B%E5%8A%A8%E7%A1%AE%E8%AE%A4%E6%B6%88%E6%81%AF"><span class="toc-number">4.2.1.5.</span> <span class="toc-text">监听器手动确认消息</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8C%87%E5%AE%9Atopic-partition-offset"><span class="toc-number">4.2.1.6.</span> <span class="toc-text">指定topic,partition,offset</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%B9%E9%87%8F%E6%B6%88%E8%B4%B9%E4%BF%A1%E6%81%AF"><span class="toc-number">4.2.1.7.</span> <span class="toc-text">批量消费信息</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E6%8B%A6%E6%88%AA%E5%99%A8"><span class="toc-number">4.2.1.8.</span> <span class="toc-text">*消息拦截器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E8%BD%AC%E5%8F%91"><span class="toc-number">4.2.1.9.</span> <span class="toc-text">消息转发</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%E6%97%B6%E7%9A%84%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5"><span class="toc-number">4.2.1.10.</span> <span class="toc-text">消息消费时的分区策略</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%BB%98%E8%AE%A4%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5"><span class="toc-number">4.2.1.10.1.</span> <span class="toc-text">默认分区策略</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#RoundRobinAssignor"><span class="toc-number">4.2.1.10.2.</span> <span class="toc-text">RoundRobinAssignor</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%A4%E4%B8%AAsticky%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5"><span class="toc-number">4.2.1.10.3.</span> <span class="toc-text">两个sticky分区策略</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%BB%BA%E8%AE%AE"><span class="toc-number">4.2.1.10.4.</span> <span class="toc-text">建议</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E7%9A%84%E5%AD%98%E5%82%A8"><span class="toc-number">4.2.2.</span> <span class="toc-text">消息的存储</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%97%A5%E5%BF%97%E6%AE%B5segment"><span class="toc-number">4.2.2.1.</span> <span class="toc-text">日志段segment</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#consumer-offsets%E5%86%85%E9%83%A8%E4%B8%BB%E9%A2%98"><span class="toc-number">4.2.2.2.</span> <span class="toc-text">__consumer_offsets内部主题</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#offset"><span class="toc-number">4.3.</span> <span class="toc-text">offset</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85offset"><span class="toc-number">4.3.1.</span> <span class="toc-text">生产者offset</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84offset"><span class="toc-number">4.3.2.</span> <span class="toc-text">消费者组offset</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%87%AA%E5%8A%A8%E6%8F%90%E4%BA%A4offset"><span class="toc-number">4.3.2.1.</span> <span class="toc-text">自动提交offset</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%8B%E5%8A%A8offset"><span class="toc-number">4.3.2.2.</span> <span class="toc-text">手动offset</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8C%87%E5%AE%9Aoffset"><span class="toc-number">4.3.2.3.</span> <span class="toc-text">指定offset</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Kafka%E9%9B%86%E7%BE%A4"><span class="toc-number">5.</span> <span class="toc-text">Kafka集群</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84"><span class="toc-number">5.1.</span> <span class="toc-text">Kafka集群架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E5%BF%B5"><span class="toc-number">5.2.</span> <span class="toc-text">概念</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ISR%E5%89%AF%E6%9C%AC"><span class="toc-number">5.2.1.</span> <span class="toc-text">ISR副本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#LEO"><span class="toc-number">5.2.2.</span> <span class="toc-text">LEO</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HW"><span class="toc-number">5.2.3.</span> <span class="toc-text">HW</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8EKraft%E6%90%AD%E5%BB%BAkafka%E9%9B%86%E7%BE%A4"><span class="toc-number">5.3.</span> <span class="toc-text">基于Kraft搭建kafka集群</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#docker-compose-yml%E6%96%87%E4%BB%B6"><span class="toc-number">5.3.1.</span> <span class="toc-text">docker-compose.yml文件</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%A1%A5%E5%85%85"><span class="toc-number">6.</span> <span class="toc-text">补充</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E7%94%9F%E4%BA%A7%E8%80%85%E5%92%8C%E6%B6%88%E8%B4%B9%E8%80%85"><span class="toc-number">6.1.</span> <span class="toc-text">自定义生产者和消费者</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85-1"><span class="toc-number">6.2.</span> <span class="toc-text">生产者</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8F%90%E9%AB%98%E7%94%9F%E4%BA%A7%E8%80%85%E5%90%9E%E5%90%90%E9%87%8F%EF%BC%88%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E5%99%A8%EF%BC%89"><span class="toc-number">6.2.1.</span> <span class="toc-text">提高生产者吞吐量（数据收集器）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sender%E7%BA%BF%E7%A8%8B"><span class="toc-number">6.2.2.</span> <span class="toc-text">Sender线程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%8F%AF%E9%9D%A0%E6%80%A7%EF%BC%88%E5%90%ABacks%E5%BA%94%E7%AD%94%EF%BC%89"><span class="toc-number">6.2.3.</span> <span class="toc-text">数据可靠性（含acks应答）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%87%8D%E5%A4%8D%EF%BC%88%E5%90%AB%E7%94%9F%E4%BA%A7%E8%80%85%E4%BA%8B%E5%8A%A1%EF%BC%89"><span class="toc-number">6.2.4.</span> <span class="toc-text">数据重复（含生产者事务）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%9C%89%E5%BA%8F%E3%80%81InFlightRequests"><span class="toc-number">6.2.5.</span> <span class="toc-text">数据有序、InFlightRequests</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Selector"><span class="toc-number">6.2.6.</span> <span class="toc-text">Selector</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E6%95%88%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE"><span class="toc-number">6.3.</span> <span class="toc-text">*高效读写数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85-1"><span class="toc-number">6.4.</span> <span class="toc-text">消费者</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E7%82%B9"><span class="toc-number">6.4.1.</span> <span class="toc-text">注意点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E6%B6%88%E8%B4%B9%E6%B5%81%E7%A8%8B"><span class="toc-number">6.4.2.</span> <span class="toc-text">消费者组消费流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%89%E6%8C%87%E5%AE%9A%E6%97%B6%E9%97%B4%E6%B6%88%E8%B4%B9"><span class="toc-number">6.4.3.</span> <span class="toc-text">按指定时间消费</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E4%BA%8B%E5%8A%A1"><span class="toc-number">6.4.4.</span> <span class="toc-text">消费者事务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%A7%AF%E5%8E%8B"><span class="toc-number">6.4.5.</span> <span class="toc-text">数据积压</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/11/Kafka/" title="JAVA学习笔记-Kafka">JAVA学习笔记-Kafka</a><time datetime="2025-04-11T04:46:00.000Z" title="Created 2025-04-11 12:46:00">2025-04-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/06/MyBatisPlus/" title="JAVA学习笔记-MyBatisPlus">JAVA学习笔记-MyBatisPlus</a><time datetime="2025-04-06T04:46:00.000Z" title="Created 2025-04-06 12:46:00">2025-04-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/05/Docker/" title="Ubuntu下Docker基本使用">Ubuntu下Docker基本使用</a><time datetime="2025-04-05T04:46:00.000Z" title="Created 2025-04-05 12:46:00">2025-04-05</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/04/docker%E8%BF%90%E8%A1%8C%E6%8A%A5%E9%94%99/" title="安装Docker后运行helloworld报错解决方案">安装Docker后运行helloworld报错解决方案</a><time datetime="2025-04-04T04:46:00.000Z" title="Created 2025-04-04 12:46:00">2025-04-04</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/03/springCloudAlibaba/" title="JAVA学习笔记-SpringCloudAlibaba">JAVA学习笔记-SpringCloudAlibaba</a><time datetime="2025-04-03T04:46:00.000Z" title="Created 2025-04-03 12:46:00">2025-04-03</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2025 By Muite</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v6.2.0" title=""><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" data-title="主题版本Butterfly_v4.3.1" title=""><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="本站项目由Github托管" title=""><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title=""><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></p>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><script async src="/js/runtime.js"></script><!-- hexo injector body_end end --></body></html>